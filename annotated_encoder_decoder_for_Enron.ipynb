{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "annotated_encoder_decoder_for_Enron.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EvaWSY/Natural-Language-Understanding/blob/master/annotated_encoder_decoder_for_Enron.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "UXThw958nGSN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# The Annotated Encoder-Decoder with Attention\n",
        "\n",
        "Recently, Alexander Rush wrote a blog post called [The Annotated Transformer](http://nlp.seas.harvard.edu/2018/04/03/attention.html), describing the Transformer model from the paper [Attention is All You Need](https://arxiv.org/abs/1706.03762). This post can be seen as a **prequel** to that: *we will implement an Encoder-Decoder with Attention* using (Gated) Recurrent Neural Networks, very closely following the original attention-based neural machine translation paper [\"Neural Machine Translation by Jointly Learning to Align and Translate\"](https://arxiv.org/abs/1409.0473) of Bahdanau et al. (2015). \n",
        "\n",
        "The idea is that going through both blog posts will make you familiar with two very influential sequence-to-sequence architectures. If you have any comments or suggestions, please let me know on Twitter [@joostbastings](https://twitter.com/joostbastings) or e-mail me at *firstname dot lastname @ gmail dot com*."
      ]
    },
    {
      "metadata": {
        "id": "7MY2XC6anGSO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Model Architecture\n",
        "\n",
        "We will model the probability $p(Y\\mid X)$ of a target sequence $Y=(y_1, \\dots, y_{N})$ given a source sequence $X=(x_1, \\dots, x_M)$ directly with a neural network: an Encoder-Decoder.\n",
        "\n",
        "<img src=\"https://github.com/bastings/annotated_encoder_decoder/blob/master/images/bahdanau.png?raw=1\" width=\"636\">\n",
        "\n",
        "#### Encoder \n",
        "\n",
        "The encoder reads in the source sentence (*at the bottom of the figure*) and produces a sequence of hidden states $\\mathbf{h}_1, \\dots, \\mathbf{h}_M$, one for each source word. These states should capture the meaning of a word in its context of the given sentence.\n",
        "\n",
        "We will use a bi-directional recurrent neural network (Bi-RNN) as the encoder; a Bi-GRU in particular.\n",
        "\n",
        "First of all we **embed** the source words. \n",
        "We simply look up the **word embedding** for each word in a (randomly initialized) lookup table.\n",
        "We will denote the word embedding for word $i$ in a given sentence with $\\mathbf{x}_i$.\n",
        "By embedding words, our model may exploit the fact that certain words (e.g. *cat* and *dog*) are semantically similar, and can be processed in a similar way.\n",
        "\n",
        "Now, how do we get hidden states $\\mathbf{h}_1, \\dots, \\mathbf{h}_M$? A forward GRU reads the source sentence left-to-right, while a backward GRU reads it right-to-left.\n",
        "Each of them follows a simple recursive formula: \n",
        "$$\\mathbf{h}_j = \\text{GRU}( \\mathbf{x}_j , \\mathbf{h}_{j - 1} )$$\n",
        "i.e. we obtain the next state from the previous state and the current input word embedding.\n",
        "\n",
        "The hidden state of the forward GRU at time step $j$ will know what words **precede** the word at that time step, but it doesn't know what words will follow. In contrast, the backward GRU will only know what words **follow** the word at time step $j$. By **concatenating** those two hidden states (*shown in blue in the figure*), we get $\\mathbf{h}_j$, which captures word $j$ in its full sentence context.\n",
        "\n",
        "\n",
        "#### Decoder \n",
        "\n",
        "The decoder (*at the top of the figure*) is a GRU with hidden state $\\mathbf{s_i}$. It follows a similar formula to the encoder, but takes one extra input $\\mathbf{c}_{i}$ (*shown in yellow*).\n",
        "\n",
        "$$\\mathbf{s}_{i} = f( \\mathbf{s}_{i - 1}, \\mathbf{y}_{i - 1}, \\mathbf{c}_i )$$\n",
        "\n",
        "Here, $\\mathbf{y}_{i - 1}$ is the previously generated target word (*not shown*).\n",
        "\n",
        "At each time step, an **attention mechanism** dynamically selects that part of the source sentence that is most relevant for predicting the current target word. It does so by comparing the last decoder state with each source hidden state. The result is a context vector $\\mathbf{c_i}$ (*shown in yellow*).\n",
        "Later the attention mechanism is explained in more detail.\n",
        "\n",
        "After computing the decoder state $\\mathbf{s}_i$, a non-linear function $g$ (which applies a [softmax](https://en.wikipedia.org/wiki/Softmax_function)) gives us the probability of the target word $y_i$ for this time step:\n",
        "\n",
        "$$ p(y_i \\mid y_{<i}, x_1^M) = g(\\mathbf{s}_i, \\mathbf{c}_i, \\mathbf{y}_{i - 1})$$\n",
        "\n",
        "Because $g$ applies a softmax, it provides a vector the size of the output vocabulary that sums to 1.0: it is a distribution over all target words. During test time, we would select the word with the highest probability for our translation.\n",
        "\n",
        "Now, for optimization, a [cross-entropy loss](https://ml-cheatsheet.readthedocs.io/en/latest/loss_functions.html#cross-entropy) is used to maximize the probability of selecting the correct word at this time step. All parameters (including word embeddings) are then updated to maximize this probability.\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "Zoiz1VNXnGSP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Prelims\n",
        "\n",
        "This tutorial requires **PyTorch >= 0.4.1** and was tested with **Python 3.6**.  \n",
        "\n",
        "Make sure you have those versions, and install the packages below if you don't have them yet."
      ]
    },
    {
      "metadata": {
        "id": "YHYvgpWInGSP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#!pip install torch numpy matplotlib sacrebleu"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "G42pxGssnGSS",
        "colab_type": "code",
        "outputId": "df900cf0-9ceb-4f88-e5de-a0710c2b4370",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import math, copy, time\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
        "from IPython.core.debugger import set_trace\n",
        "\n",
        "# we will use CUDA if it is available\n",
        "USE_CUDA = torch.cuda.is_available()\n",
        "DEVICE=torch.device('cuda:0') # or set to 'cpu'\n",
        "print(\"CUDA:\", USE_CUDA)\n",
        "print(DEVICE)\n",
        "\n",
        "seed = 42\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed(seed)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CUDA: True\n",
            "cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "xISF8XZenGSX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Let's start coding!\n",
        "\n",
        "## Model class\n",
        "\n",
        "Our base model class `EncoderDecoder` is very similar to the one in *The Annotated Transformer*.\n",
        "\n",
        "One difference is that our encoder also returns its final states (`encoder_final` below), which is used to initialize the decoder RNN. We also provide the sequence lengths as the RNNs require those."
      ]
    },
    {
      "metadata": {
        "id": "PKwBcUJsnGSX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class EncoderDecoder(nn.Module):\n",
        "    \"\"\"\n",
        "    A standard Encoder-Decoder architecture. Base for this and many \n",
        "    other models.\n",
        "    \"\"\"\n",
        "    def __init__(self, encoder, decoder, src_embed, trg_embed, generator):\n",
        "        super(EncoderDecoder, self).__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.src_embed = src_embed\n",
        "        self.trg_embed = trg_embed\n",
        "        self.generator = generator\n",
        "        \n",
        "    def forward(self, src, trg, src_mask, trg_mask, src_lengths, trg_lengths):\n",
        "        \"\"\"Take in and process masked src and target sequences.\"\"\"\n",
        "        encoder_hidden, encoder_final = self.encode(src, src_mask, src_lengths)\n",
        "        return self.decode(encoder_hidden, encoder_final, src_mask, trg, trg_mask)\n",
        "    \n",
        "    def encode(self, src, src_mask, src_lengths):\n",
        "        return self.encoder(self.src_embed(src), src_mask, src_lengths)\n",
        "    \n",
        "    def decode(self, encoder_hidden, encoder_final, src_mask, trg, trg_mask,\n",
        "               decoder_hidden=None):\n",
        "        return self.decoder(self.trg_embed(trg), encoder_hidden, encoder_final,\n",
        "                            src_mask, trg_mask, hidden=decoder_hidden)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3HGntUAHnGSZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "To keep things easy we also keep the `Generator` class the same. \n",
        "It simply projects the pre-output layer ($x$ in the `forward` function below) to obtain the output layer, so that the final dimension is the target vocabulary size."
      ]
    },
    {
      "metadata": {
        "id": "Zd6UA60InGSa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Generator(nn.Module):\n",
        "    \"\"\"Define standard linear + softmax generation step.\"\"\"\n",
        "    def __init__(self, hidden_size, vocab_size):\n",
        "        super(Generator, self).__init__()\n",
        "        self.proj = nn.Linear(hidden_size, vocab_size, bias=False)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return F.log_softmax(self.proj(x), dim=-1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Al-wpg1wnGSc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Encoder\n",
        "\n",
        "Our encoder is a bi-directional GRU. \n",
        "\n",
        "Because we want to process multiple sentences at the same time for speed reasons (it is more effcient on GPU), we need to support **mini-batches**. Sentences in a mini-batch may have different lengths, which means that the RNN needs to unroll further for certain sentences while it might already have finished for others:\n",
        "\n",
        "```\n",
        "Example: mini-batch with 3 source sentences of different lengths (7, 5, and 3).\n",
        "End-of-sequence is marked with a \"3\" here, and padding positions with \"1\".\n",
        "\n",
        "+---------------+\n",
        "| 4 5 9 8 7 8 3 |\n",
        "+---------------+\n",
        "| 5 4 8 7 3 1 1 |\n",
        "+---------------+\n",
        "| 5 8 3 1 1 1 1 |\n",
        "+---------------+\n",
        "```\n",
        "You can see that, when computing hidden states for this mini-batch, for sentence #2 and #3 we will need to stop updating the hidden state after we have encountered \"3\". We don't want to incorporate the padding values (1s).\n",
        "\n",
        "Luckily, PyTorch has convenient helper functions called `pack_padded_sequence` and `pad_packed_sequence`.\n",
        "These functions take care of masking and padding, so that the resulting word representations are simply zeros after a sentence stops.\n",
        "\n",
        "The code below reads in a source sentence (a sequence of word embeddings) and produces the hidden states.\n",
        "It also returns a final vector, a summary of the complete sentence, by concatenating the first and the last hidden states (they have both seen the whole sentence, each in a different direction). We will use the final vector to initialize the decoder."
      ]
    },
    {
      "metadata": {
        "id": "nIEgd_pCnGSe",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Encoder(nn.Module):\n",
        "    \"\"\"Encodes a sequence of word embeddings\"\"\"\n",
        "    def __init__(self, input_size, hidden_size, num_layers=1, dropout=0.):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.num_layers = num_layers\n",
        "        self.rnn = nn.GRU(input_size, hidden_size, num_layers, \n",
        "                          batch_first=True, bidirectional=True, dropout=dropout)\n",
        "        \n",
        "    def forward(self, x, mask, lengths):\n",
        "        \"\"\"\n",
        "        Applies a bidirectional GRU to sequence of embeddings x.\n",
        "        The input mini-batch x needs to be sorted by length.\n",
        "        x should have dimensions [batch, time, dim].\n",
        "        \"\"\"\n",
        "        packed = pack_padded_sequence(x, lengths, batch_first=True)\n",
        "        output, final = self.rnn(packed)\n",
        "        output, _ = pad_packed_sequence(output, batch_first=True)\n",
        "\n",
        "        # we need to manually concatenate the final states for both directions\n",
        "        fwd_final = final[0:final.size(0):2]\n",
        "        bwd_final = final[1:final.size(0):2]\n",
        "        final = torch.cat([fwd_final, bwd_final], dim=2)  # [num_layers, batch, 2*dim]\n",
        "\n",
        "        return output, final"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BR0ytFfjnGSg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Decoder\n",
        "\n",
        "The decoder is a conditional GRU. Rather than starting with an empty state like the encoder, its initial hidden state results from a projection of the encoder final vector. \n",
        "\n",
        "#### Training\n",
        "In `forward` you can find a for-loop that computes the decoder hidden states one time step at a time. \n",
        "Note that, during training, we know exactly what the target words should be! (They are in `trg_embed`.) This means that we are not even checking here what the prediction is! We simply feed the correct previous target word embedding to the GRU at each time step. This is called teacher forcing.\n",
        "\n",
        "The `forward` function returns all decoder hidden states and pre-output vectors. Elsewhere these are used to compute the loss, after which the parameters are updated.\n",
        "\n",
        "#### Prediction\n",
        "For prediction time, for forward function is only used for a single time step. After predicting a word from the returned pre-output vector, we can call it again, supplying it the word embedding of the previously predicted word and the last state."
      ]
    },
    {
      "metadata": {
        "id": "oSMi66_-nGSh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Decoder(nn.Module):\n",
        "    \"\"\"A conditional RNN decoder with attention.\"\"\"\n",
        "    \n",
        "    def __init__(self, emb_size, hidden_size, attention, num_layers=1, dropout=0.5,\n",
        "                 bridge=True):\n",
        "        super(Decoder, self).__init__()\n",
        "        \n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.attention = attention\n",
        "        self.dropout = dropout\n",
        "                 \n",
        "        self.rnn = nn.GRU(emb_size + 2*hidden_size, hidden_size, num_layers,\n",
        "                          batch_first=True, dropout=dropout)\n",
        "                 \n",
        "        # to initialize from the final encoder state\n",
        "        self.bridge = nn.Linear(2*hidden_size, hidden_size, bias=True) if bridge else None\n",
        "\n",
        "        self.dropout_layer = nn.Dropout(p=dropout)\n",
        "        self.pre_output_layer = nn.Linear(hidden_size + 2*hidden_size + emb_size,\n",
        "                                          hidden_size, bias=False)\n",
        "        \n",
        "    def forward_step(self, prev_embed, encoder_hidden, src_mask, proj_key, hidden):\n",
        "        \"\"\"Perform a single decoder step (1 word)\"\"\"\n",
        "\n",
        "        # compute context vector using attention mechanism\n",
        "        query = hidden[-1].unsqueeze(1)  # [#layers, B, D] -> [B, 1, D]\n",
        "        context, attn_probs = self.attention(\n",
        "            query=query, proj_key=proj_key,\n",
        "            value=encoder_hidden, mask=src_mask)\n",
        "\n",
        "        # update rnn hidden state\n",
        "        rnn_input = torch.cat([prev_embed, context], dim=2)\n",
        "        output, hidden = self.rnn(rnn_input, hidden)\n",
        "        \n",
        "        pre_output = torch.cat([prev_embed, output, context], dim=2)\n",
        "        pre_output = self.dropout_layer(pre_output)\n",
        "        pre_output = self.pre_output_layer(pre_output)\n",
        "\n",
        "        return output, hidden, pre_output\n",
        "    \n",
        "    def forward(self, trg_embed, encoder_hidden, encoder_final, \n",
        "                src_mask, trg_mask, hidden=None, max_len=None):\n",
        "        \"\"\"Unroll the decoder one step at a time.\"\"\"\n",
        "                                         \n",
        "        # the maximum number of steps to unroll the RNN\n",
        "        if max_len is None:\n",
        "            max_len = trg_mask.size(-1)\n",
        "\n",
        "        # initialize decoder hidden state\n",
        "        if hidden is None:\n",
        "            hidden = self.init_hidden(encoder_final)\n",
        "        \n",
        "        # pre-compute projected encoder hidden states\n",
        "        # (the \"keys\" for the attention mechanism)\n",
        "        # this is only done for efficiency\n",
        "        proj_key = self.attention.key_layer(encoder_hidden)\n",
        "        \n",
        "        # here we store all intermediate hidden states and pre-output vectors\n",
        "        decoder_states = []\n",
        "        pre_output_vectors = []\n",
        "        \n",
        "        # unroll the decoder RNN for max_len steps\n",
        "        for i in range(max_len):\n",
        "            prev_embed = trg_embed[:, i].unsqueeze(1)\n",
        "            output, hidden, pre_output = self.forward_step(\n",
        "              prev_embed, encoder_hidden, src_mask, proj_key, hidden)\n",
        "            decoder_states.append(output)\n",
        "            pre_output_vectors.append(pre_output)\n",
        "\n",
        "        decoder_states = torch.cat(decoder_states, dim=1)\n",
        "        pre_output_vectors = torch.cat(pre_output_vectors, dim=1)\n",
        "        return decoder_states, hidden, pre_output_vectors  # [B, N, D]\n",
        "\n",
        "    def init_hidden(self, encoder_final):\n",
        "        \"\"\"Returns the initial decoder state,\n",
        "        conditioned on the final encoder state.\"\"\"\n",
        "\n",
        "        if encoder_final is None:\n",
        "            return None  # start with zeros\n",
        "\n",
        "        return torch.tanh(self.bridge(encoder_final))            \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "o4kwQV64nGSk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Attention                                                                                                                                                                               \n",
        "\n",
        "At every time step, the decoder has access to *all* source word representations $\\mathbf{h}_1, \\dots, \\mathbf{h}_M$. \n",
        "An attention mechanism allows the model to focus on the currently most relevant part of the source sentence.\n",
        "The state of the decoder is represented by GRU hidden state $\\mathbf{s}_i$.\n",
        "So if we want to know which source word representation(s) $\\mathbf{h}_j$ are most relevant, we will need to define a function that takes those two things as input.\n",
        "\n",
        "Here we use the MLP-based, additive attention that was used in Bahdanau et al.:\n",
        "\n",
        "<img src=\"https://github.com/bastings/annotated_encoder_decoder/blob/master/images/attention.png?raw=1\" width=\"280\">\n",
        "\n",
        "\n",
        "We apply an MLP with tanh-activation to both the current decoder state $\\bf s_i$ (the *query*) and each encoder state $\\bf h_j$ (the *key*), and then project this to a single value (i.e. a scalar) to get the *attention energy* $e_{ij}$. \n",
        "\n",
        "Once all energies are computed, they are normalized by a softmax so that they sum to one: \n",
        "\n",
        "$$ \\alpha_{ij} = \\text{softmax}(\\mathbf{e}_i)[j] $$\n",
        "\n",
        "$$\\sum_j \\alpha_{ij} = 1.0$$ \n",
        "\n",
        "The context vector for time step $i$ is then a weighted sum of the encoder hidden states (the *values*):\n",
        "$$\\mathbf{c}_i = \\sum_j \\alpha_{ij} \\mathbf{h}_j$$"
      ]
    },
    {
      "metadata": {
        "id": "uHfjx9xInGSl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class BahdanauAttention(nn.Module):\n",
        "    \"\"\"Implements Bahdanau (MLP) attention\"\"\"\n",
        "    \n",
        "    def __init__(self, hidden_size, key_size=None, query_size=None):\n",
        "        super(BahdanauAttention, self).__init__()\n",
        "        \n",
        "        # We assume a bi-directional encoder so key_size is 2*hidden_size\n",
        "        key_size = 2 * hidden_size if key_size is None else key_size\n",
        "        query_size = hidden_size if query_size is None else query_size\n",
        "\n",
        "        self.key_layer = nn.Linear(key_size, hidden_size, bias=False)\n",
        "        self.query_layer = nn.Linear(query_size, hidden_size, bias=False)\n",
        "        self.energy_layer = nn.Linear(hidden_size, 1, bias=False)\n",
        "        \n",
        "        # to store attention scores\n",
        "        self.alphas = None\n",
        "        \n",
        "    def forward(self, query=None, proj_key=None, value=None, mask=None):\n",
        "        assert mask is not None, \"mask is required\"\n",
        "\n",
        "        # We first project the query (the decoder state).\n",
        "        # The projected keys (the encoder states) were already pre-computated.\n",
        "        query = self.query_layer(query)\n",
        "        \n",
        "        # Calculate scores.\n",
        "        scores = self.energy_layer(torch.tanh(query + proj_key))\n",
        "        scores = scores.squeeze(2).unsqueeze(1)\n",
        "        \n",
        "        # Mask out invalid positions.\n",
        "        # The mask marks valid positions so we invert it using `mask & 0`.\n",
        "        scores.data.masked_fill_(mask == 0, -float('inf'))\n",
        "        \n",
        "        # Turn scores to probabilities.\n",
        "        alphas = F.softmax(scores, dim=-1)\n",
        "        self.alphas = alphas        \n",
        "        \n",
        "        # The context vector is the weighted sum of the values.\n",
        "        context = torch.bmm(alphas, value)\n",
        "        \n",
        "        # context shape: [B, 1, 2D], alphas shape: [B, 1, M]\n",
        "        return context, alphas"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kztyUAzgnGSq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Embeddings and Softmax                                                                                                                                                                                                                                                                                           \n",
        "We use learned embeddings to convert the input tokens and output tokens to vectors of dimension `emb_size`.\n",
        "\n",
        "We will simply use PyTorch's [nn.Embedding](https://pytorch.org/docs/stable/nn.html?highlight=embedding#torch.nn.Embedding) class."
      ]
    },
    {
      "metadata": {
        "id": "LD0ymjRVnGSr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Full Model\n",
        "\n",
        "Here we define a function from hyperparameters to a full model. "
      ]
    },
    {
      "metadata": {
        "id": "iNDMZaRjnGSs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def make_model(src_vocab, tgt_vocab, emb_size=256, hidden_size=512, num_layers=1, dropout=0.1):\n",
        "    \"Helper: Construct a model from hyperparameters.\"\n",
        "\n",
        "    attention = BahdanauAttention(hidden_size)\n",
        "\n",
        "    model = EncoderDecoder(\n",
        "        Encoder(emb_size, hidden_size, num_layers=num_layers, dropout=dropout),\n",
        "        Decoder(emb_size, hidden_size, attention, num_layers=num_layers, dropout=dropout),\n",
        "        nn.Embedding(src_vocab, emb_size),\n",
        "        nn.Embedding(tgt_vocab, emb_size),\n",
        "        Generator(hidden_size, tgt_vocab))\n",
        "\n",
        "    return model.cuda() if USE_CUDA else model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "n2bcDlknnGSv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Training\n",
        "\n",
        "This section describes the training regime for our models."
      ]
    },
    {
      "metadata": {
        "id": "3Mg2Lz3QnGSw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We stop for a quick interlude to introduce some of the tools \n",
        "needed to train a standard encoder decoder model. First we define a batch object that holds the src and target sentences for training, as well as their lengths and masks. "
      ]
    },
    {
      "metadata": {
        "id": "96mlMlkWnGSz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Batches and Masking"
      ]
    },
    {
      "metadata": {
        "id": "OETxE22DnGS0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Batch:\n",
        "    \"\"\"Object for holding a batch of data with mask during training.\n",
        "    Input is a batch from a torch text iterator.\n",
        "    \"\"\"\n",
        "    def __init__(self, src, trg, pad_index=0):\n",
        "        \n",
        "        src, src_lengths = src\n",
        "        \n",
        "        self.src = src\n",
        "        self.src_lengths = src_lengths\n",
        "        self.src_mask = (src != pad_index).unsqueeze(-2)\n",
        "        self.nseqs = src.size(0)\n",
        "        \n",
        "        self.trg = None\n",
        "        self.trg_y = None\n",
        "        self.trg_mask = None\n",
        "        self.trg_lengths = None\n",
        "        self.ntokens = None\n",
        "\n",
        "        if trg is not None:\n",
        "            trg, trg_lengths = trg\n",
        "            self.trg = trg[:, :-1]\n",
        "            self.trg_lengths = trg_lengths\n",
        "            self.trg_y = trg[:, 1:]\n",
        "            self.trg_mask = (self.trg_y != pad_index)\n",
        "            self.ntokens = (self.trg_y != pad_index).data.sum().item()\n",
        "        \n",
        "        if USE_CUDA:\n",
        "            self.src = self.src.cuda()\n",
        "            self.src_mask = self.src_mask.cuda()\n",
        "\n",
        "            if trg is not None:\n",
        "                self.trg = self.trg.cuda()\n",
        "                self.trg_y = self.trg_y.cuda()\n",
        "                self.trg_mask = self.trg_mask.cuda()\n",
        "                "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LJfzmvxPnGS2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Training Loop\n",
        "The code below trains the model for 1 epoch (=1 pass through the training data)."
      ]
    },
    {
      "metadata": {
        "id": "R80_GLYVnGS3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def run_epoch(data_iter, model, loss_compute, print_every=50):\n",
        "    \"\"\"Standard Training and Logging Function\"\"\"\n",
        "\n",
        "    start = time.time()\n",
        "    total_tokens = 0\n",
        "    total_loss = 0\n",
        "    print_tokens = 0\n",
        "\n",
        "    for i, batch in enumerate(data_iter, 1):\n",
        "        \n",
        "        out, _, pre_output = model.forward(batch.src, batch.trg,\n",
        "                                           batch.src_mask, batch.trg_mask,\n",
        "                                           batch.src_lengths, batch.trg_lengths)\n",
        "        loss = loss_compute(pre_output, batch.trg_y, batch.nseqs)\n",
        "        total_loss += loss\n",
        "        total_tokens += batch.ntokens\n",
        "        print_tokens += batch.ntokens\n",
        "        \n",
        "        if model.training and i % print_every == 0:\n",
        "            elapsed = time.time() - start\n",
        "            print(\"Epoch Step: %d Loss: %f Tokens per Sec: %f\" %\n",
        "                    (i, loss / batch.nseqs, print_tokens / elapsed))\n",
        "            start = time.time()\n",
        "            print_tokens = 0\n",
        "\n",
        "    return math.exp(total_loss / float(total_tokens))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wwsxcGfRnGS4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Training Data and Batching\n",
        "\n",
        "We will use torch text for batching. This is discussed in more detail below. "
      ]
    },
    {
      "metadata": {
        "id": "-duZCbxjnGS5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Optimizer\n",
        "\n",
        "We will use the [Adam optimizer](https://arxiv.org/abs/1412.6980) with default settings ($\\beta_1=0.9$, $\\beta_2=0.999$ and $\\epsilon=10^{-8}$).\n",
        "\n",
        "We will use $0.0003$ as the learning rate here, but for different problems another learning rate may be more appropriate. You will have to tune that."
      ]
    },
    {
      "metadata": {
        "id": "PSo1Hz_KnGS5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# A First  Example (just ignore this)\n",
        "\n",
        "We can begin by trying out a simple copy-task. Given a random set of input symbols from a small vocabulary, the goal is to generate back those same symbols. "
      ]
    },
    {
      "metadata": {
        "id": "Npre0feqnGS6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Synthetic Data"
      ]
    },
    {
      "metadata": {
        "id": "mAlYh1HxnGS6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def data_gen(num_words=11, batch_size=16, num_batches=100, length=10, pad_index=0, sos_index=1):\n",
        "    \"\"\"Generate random data for a src-tgt copy task.\"\"\"\n",
        "    for i in range(num_batches):\n",
        "        data = torch.from_numpy(\n",
        "          np.random.randint(1, num_words, size=(batch_size, length)))\n",
        "        data[:, 0] = sos_index\n",
        "        data = data.cuda() if USE_CUDA else data\n",
        "        src = data[:, 1:]\n",
        "        trg = data\n",
        "        src_lengths = [length-1] * batch_size\n",
        "        trg_lengths = [length] * batch_size\n",
        "        yield Batch((src, src_lengths), (trg, trg_lengths), pad_index=pad_index)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zeRkQcaQnGS9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Loss Computation"
      ]
    },
    {
      "metadata": {
        "id": "O1Oa_6D9nGS-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class SimpleLossCompute:\n",
        "    \"\"\"A simple loss compute and train function.\"\"\"\n",
        "\n",
        "    def __init__(self, generator, criterion, opt=None):\n",
        "        self.generator = generator\n",
        "        self.criterion = criterion\n",
        "        self.opt = opt\n",
        "\n",
        "    def __call__(self, x, y, norm):\n",
        "        x = self.generator(x)\n",
        "        loss = self.criterion(x.contiguous().view(-1, x.size(-1)),\n",
        "                              y.contiguous().view(-1))\n",
        "        loss = loss / norm\n",
        "\n",
        "        if self.opt is not None:\n",
        "            loss.backward()          \n",
        "            self.opt.step()\n",
        "            self.opt.zero_grad()\n",
        "\n",
        "        return loss.data.item() * norm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FV8uVFyDnGTA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Printing examples\n",
        "\n",
        "To monitor progress during training, we will translate a few examples.\n",
        "\n",
        "We use greedy decoding for simplicity; that is, at each time step, starting at the first token, we choose the one with that maximum probability, and we never revisit that choice. "
      ]
    },
    {
      "metadata": {
        "id": "_iIh8WkSnGTB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def greedy_decode(model, src, src_mask, src_lengths, max_len=100, sos_index=1, eos_index=None):\n",
        "    \"\"\"Greedily decode a sentence.\"\"\"\n",
        "\n",
        "    with torch.no_grad():\n",
        "        encoder_hidden, encoder_final = model.encode(src, src_mask, src_lengths)\n",
        "        prev_y = torch.ones(1, 1).fill_(sos_index).type_as(src)\n",
        "        trg_mask = torch.ones_like(prev_y)\n",
        "\n",
        "    output = []\n",
        "    attention_scores = []\n",
        "    hidden = None\n",
        "\n",
        "    for i in range(max_len):\n",
        "        with torch.no_grad():\n",
        "            out, hidden, pre_output = model.decode(\n",
        "              encoder_hidden, encoder_final, src_mask,\n",
        "              prev_y, trg_mask, hidden)\n",
        "\n",
        "            # we predict from the pre-output layer, which is\n",
        "            # a combination of Decoder state, prev emb, and context\n",
        "            prob = model.generator(pre_output[:, -1])\n",
        "\n",
        "        _, next_word = torch.max(prob, dim=1)\n",
        "        next_word = next_word.data.item()\n",
        "        output.append(next_word)\n",
        "        prev_y = torch.ones(1, 1).type_as(src).fill_(next_word)\n",
        "        attention_scores.append(model.decoder.attention.alphas.cpu().numpy())\n",
        "    \n",
        "    output = np.array(output)\n",
        "        \n",
        "    # cut off everything starting from </s> \n",
        "    # (only when eos_index provided)\n",
        "    if eos_index is not None:\n",
        "        first_eos = np.where(output==eos_index)[0]\n",
        "        if len(first_eos) > 0:\n",
        "            output = output[:first_eos[0]]      \n",
        "    \n",
        "    return output, np.concatenate(attention_scores, axis=1)\n",
        "  \n",
        "\n",
        "def lookup_words(x, vocab=None):\n",
        "    if vocab is not None:\n",
        "        x = [vocab.itos[i] for i in x]\n",
        "\n",
        "    return [str(t) for t in x]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PWCm65CynGTE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def print_examples(example_iter, model, n=2, max_len=100, \n",
        "                   sos_index=1, \n",
        "                   src_eos_index=None, \n",
        "                   trg_eos_index=None, \n",
        "                   src_vocab=None, trg_vocab=None):\n",
        "    \"\"\"Prints N examples. Assumes batch size of 1.\"\"\"\n",
        "\n",
        "    model.eval()\n",
        "    count = 0\n",
        "    print()\n",
        "    \n",
        "    if src_vocab is not None and trg_vocab is not None:\n",
        "        src_eos_index = src_vocab.stoi[EOS_TOKEN]\n",
        "        trg_sos_index = trg_vocab.stoi[SOS_TOKEN]\n",
        "        trg_eos_index = trg_vocab.stoi[EOS_TOKEN]\n",
        "    else:\n",
        "        src_eos_index = None\n",
        "        trg_sos_index = 1\n",
        "        trg_eos_index = None\n",
        "        \n",
        "    for i, batch in enumerate(example_iter):\n",
        "      \n",
        "        src = batch.src.cpu().numpy()[0, :]\n",
        "        trg = batch.trg_y.cpu().numpy()[0, :]\n",
        "\n",
        "        # remove </s> (if it is there)\n",
        "        src = src[:-1] if src[-1] == src_eos_index else src\n",
        "        trg = trg[:-1] if trg[-1] == trg_eos_index else trg      \n",
        "      \n",
        "        result, _ = greedy_decode(\n",
        "          model, batch.src, batch.src_mask, batch.src_lengths,\n",
        "          max_len=max_len, sos_index=trg_sos_index, eos_index=trg_eos_index)\n",
        "        print(\"Example #%d\" % (i+1))\n",
        "        print(\"Src : \", \" \".join(lookup_words(src, vocab=src_vocab)))\n",
        "        print(\"Trg : \", \" \".join(lookup_words(trg, vocab=trg_vocab)))\n",
        "        print(\"Pred: \", \" \".join(lookup_words(result, vocab=trg_vocab)))\n",
        "        print()\n",
        "        \n",
        "        count += 1\n",
        "        if count == n:\n",
        "            break"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HEj4gpNLnGTH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Training the copy task"
      ]
    },
    {
      "metadata": {
        "scrolled": false,
        "id": "wbjeLPTknGTI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def train_copy_task():\n",
        "    \"\"\"Train the simple copy task.\"\"\"\n",
        "    num_words = 11\n",
        "    criterion = nn.NLLLoss(reduction=\"sum\", ignore_index=0)\n",
        "    model = make_model(num_words, num_words, emb_size=32, hidden_size=64)\n",
        "    optim = torch.optim.Adam(model.parameters(), lr=0.0003)\n",
        "    eval_data = list(data_gen(num_words=num_words, batch_size=1, num_batches=100))\n",
        " \n",
        "    dev_perplexities = []\n",
        "    \n",
        "    if USE_CUDA:\n",
        "        model.cuda()\n",
        "\n",
        "    for epoch in range(10):\n",
        "        \n",
        "        print(\"Epoch %d\" % epoch)\n",
        "\n",
        "        # train\n",
        "        model.train()\n",
        "        data = data_gen(num_words=num_words, batch_size=32, num_batches=100)\n",
        "        run_epoch(data, model,\n",
        "                  SimpleLossCompute(model.generator, criterion, optim))\n",
        "\n",
        "        # evaluate\n",
        "        model.eval()\n",
        "        with torch.no_grad(): \n",
        "            perplexity = run_epoch(eval_data, model,\n",
        "                                   SimpleLossCompute(model.generator, criterion, None))\n",
        "            print(\"Evaluation perplexity: %f\" % perplexity)\n",
        "            dev_perplexities.append(perplexity)\n",
        "            print_examples(eval_data, model, n=2, max_len=9)\n",
        "        \n",
        "    return dev_perplexities"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "scrolled": false,
        "id": "0lTHGxe5nGTJ",
        "colab_type": "code",
        "outputId": "4c462fb5-f7e0-4ca5-8643-81e001f8d0b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2899
        }
      },
      "cell_type": "code",
      "source": [
        "# train the copy task\n",
        "dev_perplexities = train_copy_task()\n",
        "\n",
        "def plot_perplexity(perplexities):\n",
        "    \"\"\"plot perplexities\"\"\"\n",
        "    plt.title(\"Perplexity per Epoch\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Perplexity\")\n",
        "    plt.plot(perplexities)\n",
        "    \n",
        "plot_perplexity(dev_perplexities)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py:46: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
            "  \"num_layers={}\".format(dropout, num_layers))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 0\n",
            "Epoch Step: 50 Loss: 19.669344 Tokens per Sec: 16420.981061\n",
            "Epoch Step: 100 Loss: 17.806816 Tokens per Sec: 16690.365827\n",
            "Evaluation perplexity: 7.155217\n",
            "\n",
            "Example #1\n",
            "Src :  4 8 5 7 10 3 7 8 5\n",
            "Trg :  4 8 5 7 10 3 7 8 5\n",
            "Pred:  5 8 7 5 8 7 5 5 8\n",
            "\n",
            "Example #2\n",
            "Src :  8 8 3 6 5 2 8 6 2\n",
            "Trg :  8 8 3 6 5 2 8 6 2\n",
            "Pred:  8 8 8 8 8 8 8 8 8\n",
            "\n",
            "Epoch 1\n",
            "Epoch Step: 50 Loss: 15.364892 Tokens per Sec: 16814.665998\n",
            "Epoch Step: 100 Loss: 11.802358 Tokens per Sec: 16787.666322\n",
            "Evaluation perplexity: 3.750408\n",
            "\n",
            "Example #1\n",
            "Src :  4 8 5 7 10 3 7 8 5\n",
            "Trg :  4 8 5 7 10 3 7 8 5\n",
            "Pred:  4 8 5 7 5 3 8 7 5\n",
            "\n",
            "Example #2\n",
            "Src :  8 8 3 6 5 2 8 6 2\n",
            "Trg :  8 8 3 6 5 2 8 6 2\n",
            "Pred:  8 8 3 8 2 5 8 3 2\n",
            "\n",
            "Epoch 2\n",
            "Epoch Step: 50 Loss: 10.040525 Tokens per Sec: 16771.816407\n",
            "Epoch Step: 100 Loss: 9.003312 Tokens per Sec: 16777.518927\n",
            "Evaluation perplexity: 2.564999\n",
            "\n",
            "Example #1\n",
            "Src :  4 8 5 7 10 3 7 8 5\n",
            "Trg :  4 8 5 7 10 3 7 8 5\n",
            "Pred:  4 8 5 7 3 5 8 7 5\n",
            "\n",
            "Example #2\n",
            "Src :  8 8 3 6 5 2 8 6 2\n",
            "Trg :  8 8 3 6 5 2 8 6 2\n",
            "Pred:  8 8 3 8 5 2 6 8 2\n",
            "\n",
            "Epoch 3\n",
            "Epoch Step: 50 Loss: 7.109804 Tokens per Sec: 16790.102404\n",
            "Epoch Step: 100 Loss: 6.335828 Tokens per Sec: 16726.219615\n",
            "Evaluation perplexity: 2.031718\n",
            "\n",
            "Example #1\n",
            "Src :  4 8 5 7 10 3 7 8 5\n",
            "Trg :  4 8 5 7 10 3 7 8 5\n",
            "Pred:  4 8 5 7 3 5 8 7 5\n",
            "\n",
            "Example #2\n",
            "Src :  8 8 3 6 5 2 8 6 2\n",
            "Trg :  8 8 3 6 5 2 8 6 2\n",
            "Pred:  8 8 3 6 2 5 8 8 6\n",
            "\n",
            "Epoch 4\n",
            "Epoch Step: 50 Loss: 5.750995 Tokens per Sec: 16691.205292\n",
            "Epoch Step: 100 Loss: 4.868276 Tokens per Sec: 16731.121760\n",
            "Evaluation perplexity: 1.743124\n",
            "\n",
            "Example #1\n",
            "Src :  4 8 5 7 10 3 7 8 5\n",
            "Trg :  4 8 5 7 10 3 7 8 5\n",
            "Pred:  4 8 5 7 3 5 8 7 10\n",
            "\n",
            "Example #2\n",
            "Src :  8 8 3 6 5 2 8 6 2\n",
            "Trg :  8 8 3 6 5 2 8 6 2\n",
            "Pred:  8 8 3 6 5 2 8 6 2\n",
            "\n",
            "Epoch 5\n",
            "Epoch Step: 50 Loss: 5.485379 Tokens per Sec: 16221.316006\n",
            "Epoch Step: 100 Loss: 4.179917 Tokens per Sec: 16735.651151\n",
            "Evaluation perplexity: 1.576094\n",
            "\n",
            "Example #1\n",
            "Src :  4 8 5 7 10 3 7 8 5\n",
            "Trg :  4 8 5 7 10 3 7 8 5\n",
            "Pred:  4 8 5 7 3 10 5 7 8\n",
            "\n",
            "Example #2\n",
            "Src :  8 8 3 6 5 2 8 6 2\n",
            "Trg :  8 8 3 6 5 2 8 6 2\n",
            "Pred:  8 8 3 6 5 2 8 8 6\n",
            "\n",
            "Epoch 6\n",
            "Epoch Step: 50 Loss: 4.033307 Tokens per Sec: 16369.830043\n",
            "Epoch Step: 100 Loss: 3.637259 Tokens per Sec: 16743.556800\n",
            "Evaluation perplexity: 1.447348\n",
            "\n",
            "Example #1\n",
            "Src :  4 8 5 7 10 3 7 8 5\n",
            "Trg :  4 8 5 7 10 3 7 8 5\n",
            "Pred:  4 8 5 7 10 3 5 8 7\n",
            "\n",
            "Example #2\n",
            "Src :  8 8 3 6 5 2 8 6 2\n",
            "Trg :  8 8 3 6 5 2 8 6 2\n",
            "Pred:  8 8 3 6 5 2 8 8 6\n",
            "\n",
            "Epoch 7\n",
            "Epoch Step: 50 Loss: 2.866787 Tokens per Sec: 16660.035787\n",
            "Epoch Step: 100 Loss: 2.357472 Tokens per Sec: 16623.577205\n",
            "Evaluation perplexity: 1.329341\n",
            "\n",
            "Example #1\n",
            "Src :  4 8 5 7 10 3 7 8 5\n",
            "Trg :  4 8 5 7 10 3 7 8 5\n",
            "Pred:  4 8 5 7 10 3 7 8 5\n",
            "\n",
            "Example #2\n",
            "Src :  8 8 3 6 5 2 8 6 2\n",
            "Trg :  8 8 3 6 5 2 8 6 2\n",
            "Pred:  8 8 3 6 5 2 8 6 2\n",
            "\n",
            "Epoch 8\n",
            "Epoch Step: 50 Loss: 1.990461 Tokens per Sec: 16534.829183\n",
            "Epoch Step: 100 Loss: 2.140210 Tokens per Sec: 16831.108274\n",
            "Evaluation perplexity: 1.255333\n",
            "\n",
            "Example #1\n",
            "Src :  4 8 5 7 10 3 7 8 5\n",
            "Trg :  4 8 5 7 10 3 7 8 5\n",
            "Pred:  4 8 5 7 10 3 7 8 5\n",
            "\n",
            "Example #2\n",
            "Src :  8 8 3 6 5 2 8 6 2\n",
            "Trg :  8 8 3 6 5 2 8 6 2\n",
            "Pred:  8 8 3 6 5 2 8 6 2\n",
            "\n",
            "Epoch 9\n",
            "Epoch Step: 50 Loss: 2.076617 Tokens per Sec: 16752.236554\n",
            "Epoch Step: 100 Loss: 2.136273 Tokens per Sec: 16711.313080\n",
            "Evaluation perplexity: 1.184765\n",
            "\n",
            "Example #1\n",
            "Src :  4 8 5 7 10 3 7 8 5\n",
            "Trg :  4 8 5 7 10 3 7 8 5\n",
            "Pred:  4 8 5 7 10 3 7 8 5\n",
            "\n",
            "Example #2\n",
            "Src :  8 8 3 6 5 2 8 6 2\n",
            "Trg :  8 8 3 6 5 2 8 6 2\n",
            "Pred:  8 8 3 6 5 2 8 6 2\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAEWCAYAAABliCz2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "Ff9PzjvwnGTM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "You can see that the model managed to correctly 'translate' the two examples in the end.\n",
        "\n",
        "Moreover, the perplexity of the development data nicely went down towards 1."
      ]
    },
    {
      "metadata": {
        "id": "GVuBtvCIqyGX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# With Enron Data"
      ]
    },
    {
      "metadata": {
        "id": "nr2SJCPsnGTN",
        "colab_type": "code",
        "outputId": "3690e548-7052-4d65-9618-97ef0375eb88",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 683
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install git+git://github.com/pytorch/text spacy \n",
        "!python -m spacy download en"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+git://github.com/pytorch/text\n",
            "  Cloning git://github.com/pytorch/text to /tmp/pip-req-build-u007e2s_\n",
            "Requirement already satisfied (use --upgrade to upgrade): torchtext==0.4.0 from git+git://github.com/pytorch/text in /usr/local/lib/python3.6/dist-packages\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.6/dist-packages (2.0.18)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from torchtext==0.4.0) (4.28.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from torchtext==0.4.0) (2.21.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torchtext==0.4.0) (1.0.1.post2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchtext==0.4.0) (1.16.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchtext==0.4.0) (1.12.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.2)\n",
            "Requirement already satisfied: thinc<6.13.0,>=6.12.1 in /usr/local/lib/python3.6/dist-packages (from spacy) (6.12.1)\n",
            "Requirement already satisfied: ujson>=1.35 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.35)\n",
            "Requirement already satisfied: dill<0.3,>=0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (0.2.9)\n",
            "Requirement already satisfied: plac<1.0.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy) (0.9.6)\n",
            "Requirement already satisfied: regex==2018.01.10 in /usr/local/lib/python3.6/dist-packages (from spacy) (2018.1.10)\n",
            "Requirement already satisfied: preshed<2.1.0,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from spacy) (2.0.1)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (2.0.2)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext==0.4.0) (2.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext==0.4.0) (2019.3.9)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext==0.4.0) (1.24.2)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext==0.4.0) (3.0.4)\n",
            "Requirement already satisfied: msgpack-numpy<0.4.4 in /usr/local/lib/python3.6/dist-packages (from thinc<6.13.0,>=6.12.1->spacy) (0.4.3.2)\n",
            "Requirement already satisfied: wrapt<1.11.0,>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from thinc<6.13.0,>=6.12.1->spacy) (1.10.11)\n",
            "Requirement already satisfied: cytoolz<0.10,>=0.9.0 in /usr/local/lib/python3.6/dist-packages (from thinc<6.13.0,>=6.12.1->spacy) (0.9.0.1)\n",
            "Requirement already satisfied: msgpack<0.6.0,>=0.5.6 in /usr/local/lib/python3.6/dist-packages (from thinc<6.13.0,>=6.12.1->spacy) (0.5.6)\n",
            "Requirement already satisfied: toolz>=0.8.0 in /usr/local/lib/python3.6/dist-packages (from cytoolz<0.10,>=0.9.0->thinc<6.13.0,>=6.12.1->spacy) (0.9.0)\n",
            "Building wheels for collected packages: torchtext\n",
            "  Building wheel for torchtext (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Stored in directory: /tmp/pip-ephem-wheel-cache-higaes2a/wheels/39/42/ff/82f5ccbb0f30b25e14610376f5d0c67913fc05017dab59f8eb\n",
            "Successfully built torchtext\n",
            "Requirement already satisfied: en_core_web_sm==2.0.0 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.0.0/en_core_web_sm-2.0.0.tar.gz#egg=en_core_web_sm==2.0.0 in /usr/local/lib/python3.6/dist-packages (2.0.0)\n",
            "\n",
            "\u001b[93m    Linking successful\u001b[0m\n",
            "    /usr/local/lib/python3.6/dist-packages/en_core_web_sm -->\n",
            "    /usr/local/lib/python3.6/dist-packages/spacy/data/en\n",
            "\n",
            "    You can now load the model via spacy.load('en')\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "vCnHyGqGM1ou",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import json\n",
        "drive.mount('gdrive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hu7bS9AWqxTm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from torchtext import data, vocab"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PDNsQ6QwrAnn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "DATA_PATH = 'gdrive/My Drive/NLU project/interim_data/111044_1000/'\n",
        "LARGE_DATA_PATH = 'gdrive/My Drive/NLU project/interim_data/111044/'\n",
        "\n",
        "SAMPLE_DATA_PATH = f'{LARGE_DATA_PATH}'\n",
        "PROCESSED_DATA_PATH = f'{DATA_PATH}/processed_data/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rdVRmw5grJaa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import csv\n",
        "maxInt = sys.maxsize\n",
        "\n",
        "while True:\n",
        "    # decrease the maxInt value by factor 10 \n",
        "    # as long as the OverflowError occurs.\n",
        "\n",
        "    try:\n",
        "        csv.field_size_limit(maxInt)\n",
        "        break\n",
        "    except OverflowError:\n",
        "        maxInt = int(maxInt/10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XorZV7f9nGTO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Data Loading\n",
        "\n",
        "We will load the dataset using torchtext and spacy for tokenization.\n",
        "\n",
        "This cell might take a while to run the first time, as it will download and tokenize the IWSLT data.\n",
        "\n",
        "For speed we only include short sentences, and we include a word in the vocabulary only if it occurs at least 5 times. In this case we also lowercase the data.\n",
        "\n",
        "If you have **issues** with torch text in the cell below (e.g. an `ascii` error), try running `export LC_ALL=\"en_US.UTF-8\"` before you start `jupyter notebook`."
      ]
    },
    {
      "metadata": {
        "id": "HD54q_pDnGTP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# For data loading.\n",
        "from torchtext import data, datasets\n",
        "\n",
        "if True:\n",
        "    import spacy\n",
        "    tokenizer = data.get_tokenizer('spacy')\n",
        "\n",
        "    UNK_TOKEN = \"<unk>\"\n",
        "    PAD_TOKEN = \"<pad>\"    \n",
        "    SOS_TOKEN = \"<s>\"\n",
        "    EOS_TOKEN = \"</s>\"\n",
        "    LOWER = True\n",
        "    \n",
        "    # we include lengths to provide to the RNNs\n",
        "    SRC = data.Field(tokenize=tokenizer, \n",
        "                          lower=True, include_lengths=True, batch_first=True, \n",
        "                          unk_token=UNK_TOKEN, pad_token=PAD_TOKEN, init_token=None, eos_token=EOS_TOKEN)\n",
        "    TRG = data.Field(tokenize=tokenizer, \n",
        "                          lower=True, include_lengths=True, batch_first=True,\n",
        "                          unk_token=UNK_TOKEN, pad_token=PAD_TOKEN, init_token=None, eos_token=EOS_TOKEN)\n",
        "\n",
        "\n",
        "    MAX_LEN = 500  # NOTE: we filter out a lot of sentences for speed\n",
        "#     train_data, valid_data, test_data = datasets.IWSLT.splits(\n",
        "#         exts=('.de', '.en'), fields=(SRC, TRG), \n",
        "#         filter_pred=lambda x: len(vars(x)['src']) <= MAX_LEN and \n",
        "#             len(vars(x)['trg']) <= MAX_LEN)\n",
        "\n",
        "    trn_data_fields = [(\"src\", SRC), (\"trg\", TRG)]\n",
        "    train_data, valid_data, test_data = data.TabularDataset.splits(path=f'{SAMPLE_DATA_PATH}',\n",
        "                                     train='train.csv', validation='val.csv', test='test.csv',\n",
        "                                     format='csv', skip_header=True, fields=trn_data_fields, \n",
        "                                     filter_pred=lambda x: len(vars(x)['src']) <= MAX_LEN and len(vars(x)['trg']) <= MAX_LEN)\n",
        "\n",
        "\n",
        "\n",
        "    MIN_FREQ = 5  # NOTE: we limit the vocabulary to frequent words for speed\n",
        "    SRC.build_vocab(train_data.src, min_freq=MIN_FREQ)\n",
        "    TRG.build_vocab(train_data.trg, min_freq=MIN_FREQ)\n",
        "    \n",
        "    PAD_INDEX = TRG.vocab.stoi[PAD_TOKEN]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QzaMFkmenaSg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_data[0].src[:10]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "t8Z8L-QKnGTQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Let's look at the data\n",
        "\n",
        "It never hurts to look at your data and some statistics."
      ]
    },
    {
      "metadata": {
        "id": "oEd3_FAmnGTR",
        "colab_type": "code",
        "outputId": "10573278-900e-4130-d4ed-b000e0d2a8a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1057
        }
      },
      "cell_type": "code",
      "source": [
        "def print_data_info(train_data, valid_data, test_data, src_field, trg_field):\n",
        "    \"\"\" This prints some useful stuff about our data sets. \"\"\"\n",
        "\n",
        "    print(\"Data set sizes (number of sentence pairs):\")\n",
        "    print('train', len(train_data))\n",
        "    print('valid', len(valid_data))\n",
        "    print('test', len(test_data), \"\\n\")\n",
        "\n",
        "    print(\"First training example:\")\n",
        "    print(\"src:\", \" \".join(vars(train_data[0])['src']))\n",
        "    print(\"trg:\", \" \".join(vars(train_data[0])['trg']), \"\\n\")\n",
        "\n",
        "    print(\"Most common words (src):\")\n",
        "    print(\"\\n\".join([\"%10s %10d\" % x for x in src_field.vocab.freqs.most_common(10)]), \"\\n\")\n",
        "    print(\"Most common words (trg):\")\n",
        "    print(\"\\n\".join([\"%10s %10d\" % x for x in trg_field.vocab.freqs.most_common(10)]), \"\\n\")\n",
        "\n",
        "    print(\"First 10 words (src):\")\n",
        "    print(\"\\n\".join(\n",
        "        '%02d %s' % (i, t) for i, t in enumerate(src_field.vocab.itos[:10])), \"\\n\")\n",
        "    print(\"First 10 words (trg):\")\n",
        "    print(\"\\n\".join(\n",
        "        '%02d %s' % (i, t) for i, t in enumerate(trg_field.vocab.itos[:10])), \"\\n\")\n",
        "\n",
        "    print(\"Number of Body words (types):\", len(src_field.vocab))\n",
        "    print(\"Number of Title words (types):\", len(trg_field.vocab), \"\\n\")\n",
        "    \n",
        "    \n",
        "print_data_info(train_data, valid_data, test_data, SRC, TRG)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Data set sizes (number of sentence pairs):\n",
            "train 67051\n",
            "valid 19073\n",
            "test 9569 \n",
            "\n",
            "First training example:\n",
            "src: hello vince ,   my name is bernard murphy - i received your e - mail address from les clewlow , who was my phd supervisor at the financia options research centre at warwick business school .   i 've just finished my phd on electricity price jump diffusions :   a theoretical and empirical study in incomplete markets - hence my interest in electricity price modelling and derivative pricing .   i was looking to get hold of a copy of your 1997 paper , which has recently come to my attention :   \" the challenge of pricing & risk - managing electricity derivatives \" , the us power market , risk publications , pp . 149 - 171 .   and les suggested that i contact you directly ( les is travelling at present and does n't have an electronic copy available ) to request an e - copy .   incidentally , i am lecturer in finance / financial mathematics at university of limerick ( ireland ) and have taken a year out to work for caminus uk , where i am working on introducing and developing a markets - based approach ( spark - spread ) to real asset valuations in the uk power industry .   thanks in advancve   bernard murphy\n",
            "trg: 1997 risk paper on pricing of electricity derivatives \n",
            "\n",
            "Most common words (src):\n",
            "               329279\n",
            "         .     280419\n",
            "       the     252996\n",
            "         ,     233700\n",
            "        to     181762\n",
            "         -     126269\n",
            "       and     118844\n",
            "         _     108234\n",
            "         :     104967\n",
            "        of     102249 \n",
            "\n",
            "Most common words (trg):\n",
            "         -      12563\n",
            "         :       8131\n",
            "       for       6168\n",
            "         ,       4906\n",
            "        of       3670\n",
            "         ;       3531\n",
            "         !       3423\n",
            "       and       3287\n",
            "         /       3185\n",
            "                 3058 \n",
            "\n",
            "First 10 words (src):\n",
            "00 <unk>\n",
            "01 <pad>\n",
            "02 </s>\n",
            "03  \n",
            "04 .\n",
            "05 the\n",
            "06 ,\n",
            "07 to\n",
            "08 -\n",
            "09 and \n",
            "\n",
            "First 10 words (trg):\n",
            "00 <unk>\n",
            "01 <pad>\n",
            "02 </s>\n",
            "03 -\n",
            "04 :\n",
            "05 for\n",
            "06 ,\n",
            "07 of\n",
            "08 ;\n",
            "09 ! \n",
            "\n",
            "Number of Body words (types): 32531\n",
            "Number of Title words (types): 5882 \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "uCRptO_LnGTT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Iterators\n",
        "Batching matters a ton for speed. We will use torch text's BucketIterator here to get batches containing sentences of (almost) the same length.\n",
        "\n",
        "#### Note on sorting batches for RNNs in PyTorch\n",
        "\n",
        "For effiency reasons, PyTorch RNNs require that batches have been sorted by length, with the longest sentence in the batch first. For training, we simply sort each batch. \n",
        "For validation, we would run into trouble if we want to compare our translations with some external file that was not sorted. Therefore we simply set the validation batch size to 1, so that we can keep it in the original order."
      ]
    },
    {
      "metadata": {
        "id": "DjltkIQPnGTU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_iter = data.BucketIterator(train_data, batch_size=20, train=True, \n",
        "                                 sort_within_batch=True, \n",
        "                                 sort_key=lambda x: (len(x.src), len(x.trg)), repeat=False,\n",
        "                                 device=DEVICE)\n",
        "valid_iter = data.Iterator(valid_data, batch_size=1, train=False, sort=False, repeat=False, \n",
        "                           device=DEVICE)\n",
        "\n",
        "\n",
        "def rebatch(pad_idx, batch):\n",
        "    \"\"\"Wrap torchtext batch into our own Batch class for pre-processing\"\"\"\n",
        "    return Batch(batch.src, batch.trg, pad_idx)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mmq-TPZYnGTY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Training the System\n",
        "\n",
        "Now we train the model. \n",
        "\n",
        "On a Titan X GPU, this runs at ~18,000 tokens per second with a batch size of 64."
      ]
    },
    {
      "metadata": {
        "id": "Jl6HCudZnGTZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def train(model, num_epochs=10, lr=0.0003, print_every=100):\n",
        "    \"\"\"Train a model on IWSLT\"\"\"\n",
        "    \n",
        "    if USE_CUDA:\n",
        "        model.cuda()\n",
        "\n",
        "    # optionally add label smoothing; see the Annotated Transformer\n",
        "    criterion = nn.NLLLoss(reduction=\"sum\", ignore_index=PAD_INDEX)\n",
        "    optim = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "    \n",
        "    dev_perplexities = []\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "      \n",
        "        print(\"Epoch\", epoch)\n",
        "        model.train()\n",
        "        train_perplexity = run_epoch((rebatch(PAD_INDEX, b) for b in train_iter), \n",
        "                                     model,\n",
        "                                     SimpleLossCompute(model.generator, criterion, optim),\n",
        "                                     print_every=print_every)\n",
        "        \n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            print_examples((rebatch(PAD_INDEX, x) for x in valid_iter), \n",
        "                           model, n=3, src_vocab=SRC.vocab, trg_vocab=TRG.vocab)        \n",
        "\n",
        "            dev_perplexity = run_epoch((rebatch(PAD_INDEX, b) for b in valid_iter), \n",
        "                                       model, \n",
        "                                       SimpleLossCompute(model.generator, criterion, None))\n",
        "            print(\"Validation perplexity: %f\" % dev_perplexity)\n",
        "            dev_perplexities.append(dev_perplexity)\n",
        "        \n",
        "    return dev_perplexities\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "scrolled": false,
        "id": "5bboe6POnGTe",
        "colab_type": "code",
        "outputId": "bf162f76-c3e8-4174-e3e6-75cfef5b14e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 8741
        }
      },
      "cell_type": "code",
      "source": [
        "model = make_model(len(SRC.vocab), len(TRG.vocab),\n",
        "                   emb_size=256, hidden_size=256,\n",
        "                   num_layers=1, dropout=0.2)\n",
        "dev_perplexities = train(model, print_every=100)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py:46: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
            "  \"num_layers={}\".format(dropout, num_layers))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 0\n",
            "Epoch Step: 100 Loss: 30.371017 Tokens per Sec: 2348.540385\n",
            "Epoch Step: 200 Loss: 25.343971 Tokens per Sec: 2540.076259\n",
            "Epoch Step: 300 Loss: 30.815506 Tokens per Sec: 2554.802566\n",
            "Epoch Step: 400 Loss: 23.486755 Tokens per Sec: 2589.229335\n",
            "Epoch Step: 500 Loss: 29.033417 Tokens per Sec: 2595.602924\n",
            "Epoch Step: 600 Loss: 34.188618 Tokens per Sec: 2544.648573\n",
            "Epoch Step: 700 Loss: 31.298182 Tokens per Sec: 2516.700882\n",
            "Epoch Step: 800 Loss: 23.591002 Tokens per Sec: 2560.921777\n",
            "Epoch Step: 900 Loss: 16.175261 Tokens per Sec: 2577.063542\n",
            "Epoch Step: 1000 Loss: 18.525234 Tokens per Sec: 2535.443200\n",
            "Epoch Step: 1100 Loss: 20.593403 Tokens per Sec: 2517.408730\n",
            "Epoch Step: 1200 Loss: 27.098169 Tokens per Sec: 2274.676555\n",
            "Epoch Step: 1300 Loss: 30.514240 Tokens per Sec: 2355.255602\n",
            "Epoch Step: 1400 Loss: 10.405295 Tokens per Sec: 2682.361041\n",
            "Epoch Step: 1500 Loss: 12.837216 Tokens per Sec: 2688.003173\n",
            "Epoch Step: 1600 Loss: 27.403318 Tokens per Sec: 2707.183237\n",
            "Epoch Step: 1700 Loss: 18.770975 Tokens per Sec: 2631.336963\n",
            "Epoch Step: 1800 Loss: 24.886946 Tokens per Sec: 2617.334906\n",
            "Epoch Step: 1900 Loss: 20.421644 Tokens per Sec: 2566.228493\n",
            "Epoch Step: 2000 Loss: 39.656338 Tokens per Sec: 2660.688363\n",
            "Epoch Step: 2100 Loss: 14.001697 Tokens per Sec: 2587.504772\n",
            "Epoch Step: 2200 Loss: 32.273479 Tokens per Sec: 2685.037788\n",
            "Epoch Step: 2300 Loss: 11.501164 Tokens per Sec: 2509.461453\n",
            "Epoch Step: 2400 Loss: 17.864988 Tokens per Sec: 2573.233631\n",
            "Epoch Step: 2500 Loss: 19.817598 Tokens per Sec: 2585.000669\n",
            "Epoch Step: 2600 Loss: 16.865934 Tokens per Sec: 2670.311580\n",
            "Epoch Step: 2700 Loss: 15.437947 Tokens per Sec: 2708.857860\n",
            "Epoch Step: 2800 Loss: 18.744247 Tokens per Sec: 2630.771876\n",
            "Epoch Step: 2900 Loss: 8.418776 Tokens per Sec: 2634.663028\n",
            "Epoch Step: 3000 Loss: 15.869141 Tokens per Sec: 2557.408395\n",
            "Epoch Step: 3100 Loss: 14.923215 Tokens per Sec: 2431.519946\n",
            "Epoch Step: 3200 Loss: 33.991131 Tokens per Sec: 2336.387648\n",
            "Epoch Step: 3300 Loss: 22.421120 Tokens per Sec: 2510.062754\n",
            "\n",
            "Example #1\n",
            "Src :  good afternoon mr. ball :   the enron corp. research group would like to conduct an informal interview with you at your convenience .   please give me some dates and times within the next 2 weeks that you might be available and i will arrange the schedule .   the people that will be interviewing you are :   vince kaminski    managing director stinson gibner    vice president grant masson    vice president vasant shanbhogue   vice president krishna krishnarao   director zimin lu    director tanya tamarchenko   manager alex huang    manager   each individual interview will last approximately 15 - 20 minutes , so we probably should allow at least   3 hours .   if you would prefer to call me with some dates and times - i can check the calendars while we are talking .   look forward to hearing from you .   thank you .   shirley crenshaw administrative coordinator research group 713/853 - 5290\n",
            "Trg :  with enron corp. research group\n",
            "Pred:  \n",
            "\n",
            "Example #2\n",
            "Src :  1 . if you know that you are taking vacation for the holidays , please submit a timesheet <unk> send your timesheet if you have taken time off / rotation information has changed . sorry , we are no longer tracking overtime since you are salary based . to all a / a pool members : it is important that you let us know of any time you have taken off . to those members who are sending time on to your assistant , please make sure they forward that information on to the a / a program . with the roll out of sap , you have the ability to go on - line @ http://ehronline.enron.com/ and input your time . i will continue to email for timesheets regardless if you go on - line . this is to let you know it is time to input your time or fills out your timesheet . 2 . if you have moved recently , please provide the following and indicate the new changes when sending your timesheet . new rotation : business unit and group : effective date : location : extension : supervisor : supervisor 's location : supervisor 's extension : supervisor 's assistant : assistant 's location : assistant 's extension : co # rc # 3 . quick reminder that you can pick up your check or past period check @ eb 1198 ( if they are not already coming to your location / mail stop ) . thank you for your cooperation rt\n",
            "Trg :  / a - timesheets\n",
            "Pred:  's new year\n",
            "\n",
            "Example #3\n",
            "Src :  peter and dan--   txu is in the process of amending the current guaranty to have the cap amount increased due to an increase in trading .   please review the attached document and send any commentary back to my attention .   the beneficiaries involved are both enron north america corp. and enron canada corp.   i would appreciate a prompt response in order to have the guaranty executed as soon as possible by the counterparty due to the current exposure that we currently have out to them .     thank you ,   veronica espinoza\n",
            "Trg :  energy trading -- guaranty\n",
            "Pred:  \n",
            "\n",
            "Validation perplexity: 37.916986\n",
            "Epoch 1\n",
            "Epoch Step: 100 Loss: 21.802000 Tokens per Sec: 2569.185819\n",
            "Epoch Step: 200 Loss: 25.145042 Tokens per Sec: 2561.418662\n",
            "Epoch Step: 300 Loss: 21.556105 Tokens per Sec: 2647.405794\n",
            "Epoch Step: 400 Loss: 15.105265 Tokens per Sec: 2577.094619\n",
            "Epoch Step: 500 Loss: 12.745419 Tokens per Sec: 2587.408608\n",
            "Epoch Step: 600 Loss: 25.142132 Tokens per Sec: 2409.123535\n",
            "Epoch Step: 700 Loss: 9.773890 Tokens per Sec: 2303.100603\n",
            "Epoch Step: 800 Loss: 26.850651 Tokens per Sec: 2612.530686\n",
            "Epoch Step: 900 Loss: 28.974415 Tokens per Sec: 2581.062886\n",
            "Epoch Step: 1000 Loss: 13.713099 Tokens per Sec: 2611.091384\n",
            "Epoch Step: 1100 Loss: 7.650898 Tokens per Sec: 2584.366378\n",
            "Epoch Step: 1200 Loss: 17.350559 Tokens per Sec: 2599.072656\n",
            "Epoch Step: 1300 Loss: 12.379710 Tokens per Sec: 2604.472748\n",
            "Epoch Step: 1400 Loss: 20.890448 Tokens per Sec: 2656.174373\n",
            "Epoch Step: 1500 Loss: 16.692205 Tokens per Sec: 2585.856547\n",
            "Epoch Step: 1600 Loss: 17.691771 Tokens per Sec: 2714.822486\n",
            "Epoch Step: 1700 Loss: 27.829437 Tokens per Sec: 2699.374114\n",
            "Epoch Step: 1800 Loss: 18.652304 Tokens per Sec: 2605.586835\n",
            "Epoch Step: 1900 Loss: 12.864600 Tokens per Sec: 2612.780977\n",
            "Epoch Step: 2000 Loss: 20.956282 Tokens per Sec: 2603.608199\n",
            "Epoch Step: 2100 Loss: 10.426603 Tokens per Sec: 2666.321940\n",
            "Epoch Step: 2200 Loss: 14.276400 Tokens per Sec: 2389.684602\n",
            "Epoch Step: 2300 Loss: 13.766044 Tokens per Sec: 2366.679471\n",
            "Epoch Step: 2400 Loss: 10.630414 Tokens per Sec: 2434.139697\n",
            "Epoch Step: 2500 Loss: 9.341156 Tokens per Sec: 2378.172034\n",
            "Epoch Step: 2600 Loss: 22.014814 Tokens per Sec: 2327.819666\n",
            "Epoch Step: 2700 Loss: 8.413161 Tokens per Sec: 2543.078296\n",
            "Epoch Step: 2800 Loss: 21.068058 Tokens per Sec: 2727.892434\n",
            "Epoch Step: 2900 Loss: 13.272089 Tokens per Sec: 2735.644457\n",
            "Epoch Step: 3000 Loss: 23.594076 Tokens per Sec: 2593.746964\n",
            "Epoch Step: 3100 Loss: 25.400152 Tokens per Sec: 2632.270049\n",
            "Epoch Step: 3200 Loss: 19.170557 Tokens per Sec: 2652.151547\n",
            "Epoch Step: 3300 Loss: 19.986906 Tokens per Sec: 2606.156404\n",
            "\n",
            "Example #1\n",
            "Src :  good afternoon mr. ball :   the enron corp. research group would like to conduct an informal interview with you at your convenience .   please give me some dates and times within the next 2 weeks that you might be available and i will arrange the schedule .   the people that will be interviewing you are :   vince kaminski    managing director stinson gibner    vice president grant masson    vice president vasant shanbhogue   vice president krishna krishnarao   director zimin lu    director tanya tamarchenko   manager alex huang    manager   each individual interview will last approximately 15 - 20 minutes , so we probably should allow at least   3 hours .   if you would prefer to call me with some dates and times - i can check the calendars while we are talking .   look forward to hearing from you .   thank you .   shirley crenshaw administrative coordinator research group 713/853 - 5290\n",
            "Trg :  with enron corp. research group\n",
            "Pred:  <unk>\n",
            "\n",
            "Example #2\n",
            "Src :  1 . if you know that you are taking vacation for the holidays , please submit a timesheet <unk> send your timesheet if you have taken time off / rotation information has changed . sorry , we are no longer tracking overtime since you are salary based . to all a / a pool members : it is important that you let us know of any time you have taken off . to those members who are sending time on to your assistant , please make sure they forward that information on to the a / a program . with the roll out of sap , you have the ability to go on - line @ http://ehronline.enron.com/ and input your time . i will continue to email for timesheets regardless if you go on - line . this is to let you know it is time to input your time or fills out your timesheet . 2 . if you have moved recently , please provide the following and indicate the new changes when sending your timesheet . new rotation : business unit and group : effective date : location : extension : supervisor : supervisor 's location : supervisor 's extension : supervisor 's assistant : assistant 's location : assistant 's extension : co # rc # 3 . quick reminder that you can pick up your check or past period check @ eb 1198 ( if they are not already coming to your location / mail stop ) . thank you for your cooperation rt\n",
            "Trg :  / a - timesheets\n",
            "Pred:  's new <unk>\n",
            "\n",
            "Example #3\n",
            "Src :  peter and dan--   txu is in the process of amending the current guaranty to have the cap amount increased due to an increase in trading .   please review the attached document and send any commentary back to my attention .   the beneficiaries involved are both enron north america corp. and enron canada corp.   i would appreciate a prompt response in order to have the guaranty executed as soon as possible by the counterparty due to the current exposure that we currently have out to them .     thank you ,   veronica espinoza\n",
            "Trg :  energy trading -- guaranty\n",
            "Pred:  \n",
            "\n",
            "Validation perplexity: 25.214971\n",
            "Epoch 2\n",
            "Epoch Step: 100 Loss: 14.040792 Tokens per Sec: 2366.491960\n",
            "Epoch Step: 200 Loss: 13.068735 Tokens per Sec: 2604.017930\n",
            "Epoch Step: 300 Loss: 9.566684 Tokens per Sec: 2632.027288\n",
            "Epoch Step: 400 Loss: 20.548185 Tokens per Sec: 2717.835497\n",
            "Epoch Step: 500 Loss: 14.510948 Tokens per Sec: 2637.094437\n",
            "Epoch Step: 600 Loss: 18.401615 Tokens per Sec: 2647.080232\n",
            "Epoch Step: 700 Loss: 10.744369 Tokens per Sec: 2649.372169\n",
            "Epoch Step: 800 Loss: 14.341010 Tokens per Sec: 2596.522244\n",
            "Epoch Step: 900 Loss: 3.505227 Tokens per Sec: 2712.962598\n",
            "Epoch Step: 1000 Loss: 13.685419 Tokens per Sec: 2585.705900\n",
            "Epoch Step: 1100 Loss: 15.208216 Tokens per Sec: 2610.700718\n",
            "Epoch Step: 1200 Loss: 16.934666 Tokens per Sec: 2626.544449\n",
            "Epoch Step: 1300 Loss: 12.102744 Tokens per Sec: 2672.633725\n",
            "Epoch Step: 1400 Loss: 10.976138 Tokens per Sec: 2618.032811\n",
            "Epoch Step: 1500 Loss: 20.869150 Tokens per Sec: 2515.118500\n",
            "Epoch Step: 1600 Loss: 12.822383 Tokens per Sec: 2578.403483\n",
            "Epoch Step: 1700 Loss: 17.840834 Tokens per Sec: 2637.932074\n",
            "Epoch Step: 1800 Loss: 14.870666 Tokens per Sec: 2612.947489\n",
            "Epoch Step: 1900 Loss: 8.224852 Tokens per Sec: 2295.397179\n",
            "Epoch Step: 2000 Loss: 11.894437 Tokens per Sec: 2357.687232\n",
            "Epoch Step: 2100 Loss: 12.591082 Tokens per Sec: 2614.950454\n",
            "Epoch Step: 2200 Loss: 12.617003 Tokens per Sec: 2602.523994\n",
            "Epoch Step: 2300 Loss: 20.057028 Tokens per Sec: 2626.106372\n",
            "Epoch Step: 2400 Loss: 18.883101 Tokens per Sec: 2732.128483\n",
            "Epoch Step: 2500 Loss: 6.521486 Tokens per Sec: 2617.020634\n",
            "Epoch Step: 2600 Loss: 18.517200 Tokens per Sec: 2680.064886\n",
            "Epoch Step: 2700 Loss: 8.547156 Tokens per Sec: 2586.693028\n",
            "Epoch Step: 2800 Loss: 20.365271 Tokens per Sec: 2600.752159\n",
            "Epoch Step: 2900 Loss: 11.664557 Tokens per Sec: 2640.250650\n",
            "Epoch Step: 3000 Loss: 25.116388 Tokens per Sec: 2650.559278\n",
            "Epoch Step: 3100 Loss: 18.569675 Tokens per Sec: 2666.692746\n",
            "Epoch Step: 3200 Loss: 20.922766 Tokens per Sec: 2456.980514\n",
            "Epoch Step: 3300 Loss: 18.456104 Tokens per Sec: 2286.687778\n",
            "\n",
            "Example #1\n",
            "Src :  good afternoon mr. ball :   the enron corp. research group would like to conduct an informal interview with you at your convenience .   please give me some dates and times within the next 2 weeks that you might be available and i will arrange the schedule .   the people that will be interviewing you are :   vince kaminski    managing director stinson gibner    vice president grant masson    vice president vasant shanbhogue   vice president krishna krishnarao   director zimin lu    director tanya tamarchenko   manager alex huang    manager   each individual interview will last approximately 15 - 20 minutes , so we probably should allow at least   3 hours .   if you would prefer to call me with some dates and times - i can check the calendars while we are talking .   look forward to hearing from you .   thank you .   shirley crenshaw administrative coordinator research group 713/853 - 5290\n",
            "Trg :  with enron corp. research group\n",
            "Pred:  <unk>\n",
            "\n",
            "Example #2\n",
            "Src :  1 . if you know that you are taking vacation for the holidays , please submit a timesheet <unk> send your timesheet if you have taken time off / rotation information has changed . sorry , we are no longer tracking overtime since you are salary based . to all a / a pool members : it is important that you let us know of any time you have taken off . to those members who are sending time on to your assistant , please make sure they forward that information on to the a / a program . with the roll out of sap , you have the ability to go on - line @ http://ehronline.enron.com/ and input your time . i will continue to email for timesheets regardless if you go on - line . this is to let you know it is time to input your time or fills out your timesheet . 2 . if you have moved recently , please provide the following and indicate the new changes when sending your timesheet . new rotation : business unit and group : effective date : location : extension : supervisor : supervisor 's location : supervisor 's extension : supervisor 's assistant : assistant 's location : assistant 's extension : co # rc # 3 . quick reminder that you can pick up your check or past period check @ eb 1198 ( if they are not already coming to your location / mail stop ) . thank you for your cooperation rt\n",
            "Trg :  / a - timesheets\n",
            "Pred:  's <unk>\n",
            "\n",
            "Example #3\n",
            "Src :  peter and dan--   txu is in the process of amending the current guaranty to have the cap amount increased due to an increase in trading .   please review the attached document and send any commentary back to my attention .   the beneficiaries involved are both enron north america corp. and enron canada corp.   i would appreciate a prompt response in order to have the guaranty executed as soon as possible by the counterparty due to the current exposure that we currently have out to them .     thank you ,   veronica espinoza\n",
            "Trg :  energy trading -- guaranty\n",
            "Pred:  \n",
            "\n",
            "Validation perplexity: 20.479378\n",
            "Epoch 3\n",
            "Epoch Step: 100 Loss: 11.158370 Tokens per Sec: 2555.353777\n",
            "Epoch Step: 200 Loss: 14.714511 Tokens per Sec: 2669.490196\n",
            "Epoch Step: 300 Loss: 11.295121 Tokens per Sec: 2742.718716\n",
            "Epoch Step: 400 Loss: 11.201707 Tokens per Sec: 2564.346483\n",
            "Epoch Step: 500 Loss: 10.187019 Tokens per Sec: 2592.975954\n",
            "Epoch Step: 600 Loss: 12.566231 Tokens per Sec: 2341.128145\n",
            "Epoch Step: 700 Loss: 18.596924 Tokens per Sec: 2650.664336\n",
            "Epoch Step: 800 Loss: 23.477062 Tokens per Sec: 2688.922569\n",
            "Epoch Step: 900 Loss: 8.787148 Tokens per Sec: 2631.150674\n",
            "Epoch Step: 1000 Loss: 16.236868 Tokens per Sec: 2666.944809\n",
            "Epoch Step: 1100 Loss: 8.923549 Tokens per Sec: 2658.264294\n",
            "Epoch Step: 1200 Loss: 8.160586 Tokens per Sec: 2586.181726\n",
            "Epoch Step: 1300 Loss: 16.947676 Tokens per Sec: 2328.667381\n",
            "Epoch Step: 1400 Loss: 22.963644 Tokens per Sec: 2426.592406\n",
            "Epoch Step: 1500 Loss: 14.950235 Tokens per Sec: 2577.155938\n",
            "Epoch Step: 1600 Loss: 13.107120 Tokens per Sec: 2664.419003\n",
            "Epoch Step: 1700 Loss: 15.116611 Tokens per Sec: 2645.318451\n",
            "Epoch Step: 1800 Loss: 11.014297 Tokens per Sec: 2593.167387\n",
            "Epoch Step: 1900 Loss: 12.496707 Tokens per Sec: 2627.314961\n",
            "Epoch Step: 2000 Loss: 15.135620 Tokens per Sec: 2646.027680\n",
            "Epoch Step: 2100 Loss: 15.163039 Tokens per Sec: 2634.401768\n",
            "Epoch Step: 2200 Loss: 16.951498 Tokens per Sec: 2652.270579\n",
            "Epoch Step: 2300 Loss: 7.065808 Tokens per Sec: 2626.457200\n",
            "Epoch Step: 2400 Loss: 14.469464 Tokens per Sec: 2678.461644\n",
            "Epoch Step: 2500 Loss: 8.707847 Tokens per Sec: 2581.928346\n",
            "Epoch Step: 2600 Loss: 11.562358 Tokens per Sec: 2636.926451\n",
            "Epoch Step: 2700 Loss: 14.961860 Tokens per Sec: 2695.650528\n",
            "Epoch Step: 2800 Loss: 17.676512 Tokens per Sec: 2617.266788\n",
            "Epoch Step: 2900 Loss: 9.841986 Tokens per Sec: 2609.938486\n",
            "Epoch Step: 3000 Loss: 16.410482 Tokens per Sec: 2650.313866\n",
            "Epoch Step: 3100 Loss: 17.423109 Tokens per Sec: 2558.719721\n",
            "Epoch Step: 3200 Loss: 7.386956 Tokens per Sec: 2353.537459\n",
            "Epoch Step: 3300 Loss: 12.159083 Tokens per Sec: 2321.332944\n",
            "\n",
            "Example #1\n",
            "Src :  good afternoon mr. ball :   the enron corp. research group would like to conduct an informal interview with you at your convenience .   please give me some dates and times within the next 2 weeks that you might be available and i will arrange the schedule .   the people that will be interviewing you are :   vince kaminski    managing director stinson gibner    vice president grant masson    vice president vasant shanbhogue   vice president krishna krishnarao   director zimin lu    director tanya tamarchenko   manager alex huang    manager   each individual interview will last approximately 15 - 20 minutes , so we probably should allow at least   3 hours .   if you would prefer to call me with some dates and times - i can check the calendars while we are talking .   look forward to hearing from you .   thank you .   shirley crenshaw administrative coordinator research group 713/853 - 5290\n",
            "Trg :  with enron corp. research group\n",
            "Pred:  <unk> interview with enron\n",
            "\n",
            "Example #2\n",
            "Src :  1 . if you know that you are taking vacation for the holidays , please submit a timesheet <unk> send your timesheet if you have taken time off / rotation information has changed . sorry , we are no longer tracking overtime since you are salary based . to all a / a pool members : it is important that you let us know of any time you have taken off . to those members who are sending time on to your assistant , please make sure they forward that information on to the a / a program . with the roll out of sap , you have the ability to go on - line @ http://ehronline.enron.com/ and input your time . i will continue to email for timesheets regardless if you go on - line . this is to let you know it is time to input your time or fills out your timesheet . 2 . if you have moved recently , please provide the following and indicate the new changes when sending your timesheet . new rotation : business unit and group : effective date : location : extension : supervisor : supervisor 's location : supervisor 's extension : supervisor 's assistant : assistant 's location : assistant 's extension : co # rc # 3 . quick reminder that you can pick up your check or past period check @ eb 1198 ( if they are not already coming to your location / mail stop ) . thank you for your cooperation rt\n",
            "Trg :  / a - timesheets\n",
            "Pred:  <unk>\n",
            "\n",
            "Example #3\n",
            "Src :  peter and dan--   txu is in the process of amending the current guaranty to have the cap amount increased due to an increase in trading .   please review the attached document and send any commentary back to my attention .   the beneficiaries involved are both enron north america corp. and enron canada corp.   i would appreciate a prompt response in order to have the guaranty executed as soon as possible by the counterparty due to the current exposure that we currently have out to them .     thank you ,   veronica espinoza\n",
            "Trg :  energy trading -- guaranty\n",
            "Pred:  \n",
            "\n",
            "Validation perplexity: 18.932391\n",
            "Epoch 4\n",
            "Epoch Step: 100 Loss: 9.174450 Tokens per Sec: 2600.618917\n",
            "Epoch Step: 200 Loss: 15.330579 Tokens per Sec: 2639.299994\n",
            "Epoch Step: 300 Loss: 14.288370 Tokens per Sec: 2595.432918\n",
            "Epoch Step: 400 Loss: 7.041927 Tokens per Sec: 2591.949726\n",
            "Epoch Step: 500 Loss: 11.102430 Tokens per Sec: 2625.951646\n",
            "Epoch Step: 600 Loss: 15.442963 Tokens per Sec: 2454.759596\n",
            "Epoch Step: 700 Loss: 11.086455 Tokens per Sec: 2410.372658\n",
            "Epoch Step: 800 Loss: 15.750949 Tokens per Sec: 2331.547557\n",
            "Epoch Step: 900 Loss: 9.581506 Tokens per Sec: 2596.202900\n",
            "Epoch Step: 1000 Loss: 7.944654 Tokens per Sec: 2626.989753\n",
            "Epoch Step: 1100 Loss: 7.507371 Tokens per Sec: 2594.132020\n",
            "Epoch Step: 1200 Loss: 14.673433 Tokens per Sec: 2603.004707\n",
            "Epoch Step: 1300 Loss: 11.047481 Tokens per Sec: 2654.867028\n",
            "Epoch Step: 1400 Loss: 15.079712 Tokens per Sec: 2547.406085\n",
            "Epoch Step: 1500 Loss: 14.128516 Tokens per Sec: 2318.994424\n",
            "Epoch Step: 1600 Loss: 11.549054 Tokens per Sec: 2739.984565\n",
            "Epoch Step: 1700 Loss: 8.005287 Tokens per Sec: 2634.365809\n",
            "Epoch Step: 1800 Loss: 14.270741 Tokens per Sec: 2651.208843\n",
            "Epoch Step: 1900 Loss: 14.607407 Tokens per Sec: 2645.274226\n",
            "Epoch Step: 2000 Loss: 18.917101 Tokens per Sec: 2562.307300\n",
            "Epoch Step: 2100 Loss: 17.856813 Tokens per Sec: 2609.367139\n",
            "Epoch Step: 2200 Loss: 15.807343 Tokens per Sec: 2636.319655\n",
            "Epoch Step: 2300 Loss: 17.197460 Tokens per Sec: 2573.466635\n",
            "Epoch Step: 2400 Loss: 19.841940 Tokens per Sec: 2576.891187\n",
            "Epoch Step: 2500 Loss: 23.265371 Tokens per Sec: 2498.924359\n",
            "Epoch Step: 2600 Loss: 14.901250 Tokens per Sec: 2327.750989\n",
            "Epoch Step: 2700 Loss: 21.884893 Tokens per Sec: 2491.468038\n",
            "Epoch Step: 2800 Loss: 9.464778 Tokens per Sec: 2637.551573\n",
            "Epoch Step: 2900 Loss: 10.282300 Tokens per Sec: 2708.092631\n",
            "Epoch Step: 3000 Loss: 22.579575 Tokens per Sec: 2666.335845\n",
            "Epoch Step: 3100 Loss: 5.565300 Tokens per Sec: 2653.859417\n",
            "Epoch Step: 3200 Loss: 5.591527 Tokens per Sec: 2564.419142\n",
            "Epoch Step: 3300 Loss: 8.681844 Tokens per Sec: 2592.674994\n",
            "\n",
            "Example #1\n",
            "Src :  good afternoon mr. ball :   the enron corp. research group would like to conduct an informal interview with you at your convenience .   please give me some dates and times within the next 2 weeks that you might be available and i will arrange the schedule .   the people that will be interviewing you are :   vince kaminski    managing director stinson gibner    vice president grant masson    vice president vasant shanbhogue   vice president krishna krishnarao   director zimin lu    director tanya tamarchenko   manager alex huang    manager   each individual interview will last approximately 15 - 20 minutes , so we probably should allow at least   3 hours .   if you would prefer to call me with some dates and times - i can check the calendars while we are talking .   look forward to hearing from you .   thank you .   shirley crenshaw administrative coordinator research group 713/853 - 5290\n",
            "Trg :  with enron corp. research group\n",
            "Pred:  enron research group\n",
            "\n",
            "Example #2\n",
            "Src :  1 . if you know that you are taking vacation for the holidays , please submit a timesheet <unk> send your timesheet if you have taken time off / rotation information has changed . sorry , we are no longer tracking overtime since you are salary based . to all a / a pool members : it is important that you let us know of any time you have taken off . to those members who are sending time on to your assistant , please make sure they forward that information on to the a / a program . with the roll out of sap , you have the ability to go on - line @ http://ehronline.enron.com/ and input your time . i will continue to email for timesheets regardless if you go on - line . this is to let you know it is time to input your time or fills out your timesheet . 2 . if you have moved recently , please provide the following and indicate the new changes when sending your timesheet . new rotation : business unit and group : effective date : location : extension : supervisor : supervisor 's location : supervisor 's extension : supervisor 's assistant : assistant 's location : assistant 's extension : co # rc # 3 . quick reminder that you can pick up your check or past period check @ eb 1198 ( if they are not already coming to your location / mail stop ) . thank you for your cooperation rt\n",
            "Trg :  / a - timesheets\n",
            "Pred:  's <unk>\n",
            "\n",
            "Example #3\n",
            "Src :  peter and dan--   txu is in the process of amending the current guaranty to have the cap amount increased due to an increase in trading .   please review the attached document and send any commentary back to my attention .   the beneficiaries involved are both enron north america corp. and enron canada corp.   i would appreciate a prompt response in order to have the guaranty executed as soon as possible by the counterparty due to the current exposure that we currently have out to them .     thank you ,   veronica espinoza\n",
            "Trg :  energy trading -- guaranty\n",
            "Pred:  \n",
            "\n",
            "Validation perplexity: 18.374452\n",
            "Epoch 5\n",
            "Epoch Step: 100 Loss: 9.931939 Tokens per Sec: 2323.375329\n",
            "Epoch Step: 200 Loss: 10.776196 Tokens per Sec: 2457.002212\n",
            "Epoch Step: 300 Loss: 13.084557 Tokens per Sec: 2682.704106\n",
            "Epoch Step: 400 Loss: 15.393447 Tokens per Sec: 2683.709170\n",
            "Epoch Step: 500 Loss: 5.745166 Tokens per Sec: 2659.857761\n",
            "Epoch Step: 600 Loss: 8.963851 Tokens per Sec: 2647.081052\n",
            "Epoch Step: 700 Loss: 7.776624 Tokens per Sec: 2587.486777\n",
            "Epoch Step: 800 Loss: 8.817672 Tokens per Sec: 2556.765885\n",
            "Epoch Step: 900 Loss: 7.573726 Tokens per Sec: 2583.766515\n",
            "Epoch Step: 1000 Loss: 23.027460 Tokens per Sec: 2529.065801\n",
            "Epoch Step: 1100 Loss: 9.945196 Tokens per Sec: 2621.063579\n",
            "Epoch Step: 1200 Loss: 13.627593 Tokens per Sec: 2580.984607\n",
            "Epoch Step: 1300 Loss: 7.619129 Tokens per Sec: 2708.074813\n",
            "Epoch Step: 1400 Loss: 8.830441 Tokens per Sec: 2674.560092\n",
            "Epoch Step: 1500 Loss: 12.587518 Tokens per Sec: 2641.527898\n",
            "Epoch Step: 1600 Loss: 14.142290 Tokens per Sec: 2579.485992\n",
            "Epoch Step: 1700 Loss: 7.091926 Tokens per Sec: 2602.873820\n",
            "Epoch Step: 1800 Loss: 8.708171 Tokens per Sec: 2617.151350\n",
            "Epoch Step: 1900 Loss: 8.243743 Tokens per Sec: 2554.308704\n",
            "Epoch Step: 2000 Loss: 7.002136 Tokens per Sec: 2409.935326\n",
            "Epoch Step: 2100 Loss: 11.640574 Tokens per Sec: 2390.938117\n",
            "Epoch Step: 2200 Loss: 9.019217 Tokens per Sec: 2523.325735\n",
            "Epoch Step: 2300 Loss: 12.949611 Tokens per Sec: 2457.821938\n",
            "Epoch Step: 2400 Loss: 11.101991 Tokens per Sec: 2324.328168\n",
            "Epoch Step: 2500 Loss: 7.757866 Tokens per Sec: 2633.586456\n",
            "Epoch Step: 2600 Loss: 13.817746 Tokens per Sec: 2586.721104\n",
            "Epoch Step: 2700 Loss: 6.818078 Tokens per Sec: 2558.934509\n",
            "Epoch Step: 2800 Loss: 11.235333 Tokens per Sec: 2572.638664\n",
            "Epoch Step: 2900 Loss: 12.980094 Tokens per Sec: 2546.634555\n",
            "Epoch Step: 3000 Loss: 6.305192 Tokens per Sec: 2624.105812\n",
            "Epoch Step: 3100 Loss: 11.416297 Tokens per Sec: 2687.795480\n",
            "Epoch Step: 3200 Loss: 12.026293 Tokens per Sec: 2619.110201\n",
            "Epoch Step: 3300 Loss: 12.587362 Tokens per Sec: 2595.787677\n",
            "\n",
            "Example #1\n",
            "Src :  good afternoon mr. ball :   the enron corp. research group would like to conduct an informal interview with you at your convenience .   please give me some dates and times within the next 2 weeks that you might be available and i will arrange the schedule .   the people that will be interviewing you are :   vince kaminski    managing director stinson gibner    vice president grant masson    vice president vasant shanbhogue   vice president krishna krishnarao   director zimin lu    director tanya tamarchenko   manager alex huang    manager   each individual interview will last approximately 15 - 20 minutes , so we probably should allow at least   3 hours .   if you would prefer to call me with some dates and times - i can check the calendars while we are talking .   look forward to hearing from you .   thank you .   shirley crenshaw administrative coordinator research group 713/853 - 5290\n",
            "Trg :  with enron corp. research group\n",
            "Pred:  <unk>\n",
            "\n",
            "Example #2\n",
            "Src :  1 . if you know that you are taking vacation for the holidays , please submit a timesheet <unk> send your timesheet if you have taken time off / rotation information has changed . sorry , we are no longer tracking overtime since you are salary based . to all a / a pool members : it is important that you let us know of any time you have taken off . to those members who are sending time on to your assistant , please make sure they forward that information on to the a / a program . with the roll out of sap , you have the ability to go on - line @ http://ehronline.enron.com/ and input your time . i will continue to email for timesheets regardless if you go on - line . this is to let you know it is time to input your time or fills out your timesheet . 2 . if you have moved recently , please provide the following and indicate the new changes when sending your timesheet . new rotation : business unit and group : effective date : location : extension : supervisor : supervisor 's location : supervisor 's extension : supervisor 's assistant : assistant 's location : assistant 's extension : co # rc # 3 . quick reminder that you can pick up your check or past period check @ eb 1198 ( if they are not already coming to your location / mail stop ) . thank you for your cooperation rt\n",
            "Trg :  / a - timesheets\n",
            "Pred:  's new year\n",
            "\n",
            "Example #3\n",
            "Src :  peter and dan--   txu is in the process of amending the current guaranty to have the cap amount increased due to an increase in trading .   please review the attached document and send any commentary back to my attention .   the beneficiaries involved are both enron north america corp. and enron canada corp.   i would appreciate a prompt response in order to have the guaranty executed as soon as possible by the counterparty due to the current exposure that we currently have out to them .     thank you ,   veronica espinoza\n",
            "Trg :  energy trading -- guaranty\n",
            "Pred:  \n",
            "\n",
            "Validation perplexity: 18.809648\n",
            "Epoch 6\n",
            "Epoch Step: 100 Loss: 8.714049 Tokens per Sec: 2465.000700\n",
            "Epoch Step: 200 Loss: 8.154227 Tokens per Sec: 2629.056976\n",
            "Epoch Step: 300 Loss: 7.110725 Tokens per Sec: 2723.012252\n",
            "Epoch Step: 400 Loss: 14.816829 Tokens per Sec: 2617.865087\n",
            "Epoch Step: 500 Loss: 12.505428 Tokens per Sec: 2562.447005\n",
            "Epoch Step: 600 Loss: 2.426071 Tokens per Sec: 2709.393722\n",
            "Epoch Step: 700 Loss: 11.519548 Tokens per Sec: 2588.980638\n",
            "Epoch Step: 800 Loss: 14.643758 Tokens per Sec: 2615.915591\n",
            "Epoch Step: 900 Loss: 9.650317 Tokens per Sec: 2664.784287\n",
            "Epoch Step: 1000 Loss: 6.917990 Tokens per Sec: 2604.401743\n",
            "Epoch Step: 1100 Loss: 12.008265 Tokens per Sec: 2653.629493\n",
            "Epoch Step: 1200 Loss: 13.765124 Tokens per Sec: 2563.434040\n",
            "Epoch Step: 1300 Loss: 8.351657 Tokens per Sec: 2350.220051\n",
            "Epoch Step: 1400 Loss: 14.387542 Tokens per Sec: 2316.355248\n",
            "Epoch Step: 1500 Loss: 5.738069 Tokens per Sec: 2652.014623\n",
            "Epoch Step: 1600 Loss: 10.438437 Tokens per Sec: 2684.684382\n",
            "Epoch Step: 1700 Loss: 9.190416 Tokens per Sec: 2492.715178\n",
            "Epoch Step: 1800 Loss: 11.820976 Tokens per Sec: 2495.608220\n",
            "Epoch Step: 1900 Loss: 7.313687 Tokens per Sec: 2600.912262\n",
            "Epoch Step: 2000 Loss: 10.669505 Tokens per Sec: 2635.284008\n",
            "Epoch Step: 2100 Loss: 8.846467 Tokens per Sec: 2586.846546\n",
            "Epoch Step: 2200 Loss: 7.845901 Tokens per Sec: 2644.474284\n",
            "Epoch Step: 2300 Loss: 4.707082 Tokens per Sec: 2695.297723\n",
            "Epoch Step: 2400 Loss: 8.265239 Tokens per Sec: 2724.223505\n",
            "Epoch Step: 2500 Loss: 6.999132 Tokens per Sec: 2603.232563\n",
            "Epoch Step: 2600 Loss: 9.118370 Tokens per Sec: 2552.982807\n",
            "Epoch Step: 2700 Loss: 13.196187 Tokens per Sec: 2580.571750\n",
            "Epoch Step: 2800 Loss: 7.216707 Tokens per Sec: 2623.262914\n",
            "Epoch Step: 2900 Loss: 5.323346 Tokens per Sec: 2585.842577\n",
            "Epoch Step: 3000 Loss: 12.767136 Tokens per Sec: 2594.189987\n",
            "Epoch Step: 3100 Loss: 10.099211 Tokens per Sec: 2566.947085\n",
            "Epoch Step: 3200 Loss: 8.642183 Tokens per Sec: 2372.088168\n",
            "Epoch Step: 3300 Loss: 13.505960 Tokens per Sec: 2317.304739\n",
            "\n",
            "Example #1\n",
            "Src :  good afternoon mr. ball :   the enron corp. research group would like to conduct an informal interview with you at your convenience .   please give me some dates and times within the next 2 weeks that you might be available and i will arrange the schedule .   the people that will be interviewing you are :   vince kaminski    managing director stinson gibner    vice president grant masson    vice president vasant shanbhogue   vice president krishna krishnarao   director zimin lu    director tanya tamarchenko   manager alex huang    manager   each individual interview will last approximately 15 - 20 minutes , so we probably should allow at least   3 hours .   if you would prefer to call me with some dates and times - i can check the calendars while we are talking .   look forward to hearing from you .   thank you .   shirley crenshaw administrative coordinator research group 713/853 - 5290\n",
            "Trg :  with enron corp. research group\n",
            "Pred:  's resume\n",
            "\n",
            "Example #2\n",
            "Src :  1 . if you know that you are taking vacation for the holidays , please submit a timesheet <unk> send your timesheet if you have taken time off / rotation information has changed . sorry , we are no longer tracking overtime since you are salary based . to all a / a pool members : it is important that you let us know of any time you have taken off . to those members who are sending time on to your assistant , please make sure they forward that information on to the a / a program . with the roll out of sap , you have the ability to go on - line @ http://ehronline.enron.com/ and input your time . i will continue to email for timesheets regardless if you go on - line . this is to let you know it is time to input your time or fills out your timesheet . 2 . if you have moved recently , please provide the following and indicate the new changes when sending your timesheet . new rotation : business unit and group : effective date : location : extension : supervisor : supervisor 's location : supervisor 's extension : supervisor 's assistant : assistant 's location : assistant 's extension : co # rc # 3 . quick reminder that you can pick up your check or past period check @ eb 1198 ( if they are not already coming to your location / mail stop ) . thank you for your cooperation rt\n",
            "Trg :  / a - timesheets\n",
            "Pred:  <unk> for the weekend of <unk>\n",
            "\n",
            "Example #3\n",
            "Src :  peter and dan--   txu is in the process of amending the current guaranty to have the cap amount increased due to an increase in trading .   please review the attached document and send any commentary back to my attention .   the beneficiaries involved are both enron north america corp. and enron canada corp.   i would appreciate a prompt response in order to have the guaranty executed as soon as possible by the counterparty due to the current exposure that we currently have out to them .     thank you ,   veronica espinoza\n",
            "Trg :  energy trading -- guaranty\n",
            "Pred:  \n",
            "\n",
            "Validation perplexity: 20.282485\n",
            "Epoch 7\n",
            "Epoch Step: 100 Loss: 9.074705 Tokens per Sec: 2514.792972\n",
            "Epoch Step: 200 Loss: 1.733754 Tokens per Sec: 2499.148125\n",
            "Epoch Step: 300 Loss: 12.100001 Tokens per Sec: 2558.638887\n",
            "Epoch Step: 400 Loss: 4.903539 Tokens per Sec: 2550.611685\n",
            "Epoch Step: 500 Loss: 9.497104 Tokens per Sec: 2569.870260\n",
            "Epoch Step: 600 Loss: 5.414572 Tokens per Sec: 2553.684521\n",
            "Epoch Step: 700 Loss: 4.035221 Tokens per Sec: 2360.391093\n",
            "Epoch Step: 800 Loss: 7.159013 Tokens per Sec: 2424.819351\n",
            "Epoch Step: 900 Loss: 6.698846 Tokens per Sec: 2434.042593\n",
            "Epoch Step: 1000 Loss: 7.622132 Tokens per Sec: 2309.493303\n",
            "Epoch Step: 1100 Loss: 7.215924 Tokens per Sec: 2392.605559\n",
            "Epoch Step: 1200 Loss: 17.068600 Tokens per Sec: 2579.099330\n",
            "Epoch Step: 1300 Loss: 9.056829 Tokens per Sec: 2650.396502\n",
            "Epoch Step: 1400 Loss: 4.073847 Tokens per Sec: 2620.316314\n",
            "Epoch Step: 1500 Loss: 5.224677 Tokens per Sec: 2725.349255\n",
            "Epoch Step: 1600 Loss: 8.792591 Tokens per Sec: 2600.857235\n",
            "Epoch Step: 1700 Loss: 10.323072 Tokens per Sec: 2585.808192\n",
            "Epoch Step: 1800 Loss: 7.470845 Tokens per Sec: 2687.543298\n",
            "Epoch Step: 1900 Loss: 7.243816 Tokens per Sec: 2520.928412\n",
            "Epoch Step: 2000 Loss: 7.644307 Tokens per Sec: 2624.072305\n",
            "Epoch Step: 2100 Loss: 4.772020 Tokens per Sec: 2679.637603\n",
            "Epoch Step: 2200 Loss: 14.974367 Tokens per Sec: 2611.888565\n",
            "Epoch Step: 2300 Loss: 4.245668 Tokens per Sec: 2567.748168\n",
            "Epoch Step: 2400 Loss: 16.059692 Tokens per Sec: 2647.395564\n",
            "Epoch Step: 2500 Loss: 9.904968 Tokens per Sec: 2487.328676\n",
            "Epoch Step: 2600 Loss: 11.472410 Tokens per Sec: 2356.278792\n",
            "Epoch Step: 2700 Loss: 5.995524 Tokens per Sec: 2443.724838\n",
            "Epoch Step: 2800 Loss: 3.912551 Tokens per Sec: 2704.813412\n",
            "Epoch Step: 2900 Loss: 8.191983 Tokens per Sec: 2486.412183\n",
            "Epoch Step: 3000 Loss: 4.736380 Tokens per Sec: 2616.446039\n",
            "Epoch Step: 3100 Loss: 6.140108 Tokens per Sec: 2551.426698\n",
            "Epoch Step: 3200 Loss: 6.869984 Tokens per Sec: 2590.044693\n",
            "Epoch Step: 3300 Loss: 6.297182 Tokens per Sec: 2650.691942\n",
            "\n",
            "Example #1\n",
            "Src :  good afternoon mr. ball :   the enron corp. research group would like to conduct an informal interview with you at your convenience .   please give me some dates and times within the next 2 weeks that you might be available and i will arrange the schedule .   the people that will be interviewing you are :   vince kaminski    managing director stinson gibner    vice president grant masson    vice president vasant shanbhogue   vice president krishna krishnarao   director zimin lu    director tanya tamarchenko   manager alex huang    manager   each individual interview will last approximately 15 - 20 minutes , so we probably should allow at least   3 hours .   if you would prefer to call me with some dates and times - i can check the calendars while we are talking .   look forward to hearing from you .   thank you .   shirley crenshaw administrative coordinator research group 713/853 - 5290\n",
            "Trg :  with enron corp. research group\n",
            "Pred:  enron analyst program\n",
            "\n",
            "Example #2\n",
            "Src :  1 . if you know that you are taking vacation for the holidays , please submit a timesheet <unk> send your timesheet if you have taken time off / rotation information has changed . sorry , we are no longer tracking overtime since you are salary based . to all a / a pool members : it is important that you let us know of any time you have taken off . to those members who are sending time on to your assistant , please make sure they forward that information on to the a / a program . with the roll out of sap , you have the ability to go on - line @ http://ehronline.enron.com/ and input your time . i will continue to email for timesheets regardless if you go on - line . this is to let you know it is time to input your time or fills out your timesheet . 2 . if you have moved recently , please provide the following and indicate the new changes when sending your timesheet . new rotation : business unit and group : effective date : location : extension : supervisor : supervisor 's location : supervisor 's extension : supervisor 's assistant : assistant 's location : assistant 's extension : co # rc # 3 . quick reminder that you can pick up your check or past period check @ eb 1198 ( if they are not already coming to your location / mail stop ) . thank you for your cooperation rt\n",
            "Trg :  / a - timesheets\n",
            "Pred:  <unk> / <unk> / <unk>\n",
            "\n",
            "Example #3\n",
            "Src :  peter and dan--   txu is in the process of amending the current guaranty to have the cap amount increased due to an increase in trading .   please review the attached document and send any commentary back to my attention .   the beneficiaries involved are both enron north america corp. and enron canada corp.   i would appreciate a prompt response in order to have the guaranty executed as soon as possible by the counterparty due to the current exposure that we currently have out to them .     thank you ,   veronica espinoza\n",
            "Trg :  energy trading -- guaranty\n",
            "Pred:  \n",
            "\n",
            "Validation perplexity: 22.674804\n",
            "Epoch 8\n",
            "Epoch Step: 100 Loss: 4.966638 Tokens per Sec: 2280.885742\n",
            "Epoch Step: 200 Loss: 5.801080 Tokens per Sec: 2538.427145\n",
            "Epoch Step: 300 Loss: 3.550627 Tokens per Sec: 2574.778764\n",
            "Epoch Step: 400 Loss: 7.604006 Tokens per Sec: 2600.615890\n",
            "Epoch Step: 500 Loss: 4.923227 Tokens per Sec: 2698.024787\n",
            "Epoch Step: 600 Loss: 10.382490 Tokens per Sec: 2660.908606\n",
            "Epoch Step: 700 Loss: 5.322748 Tokens per Sec: 2655.508979\n",
            "Epoch Step: 800 Loss: 5.458543 Tokens per Sec: 2641.889882\n",
            "Epoch Step: 900 Loss: 5.542087 Tokens per Sec: 2495.245639\n",
            "Epoch Step: 1000 Loss: 12.370814 Tokens per Sec: 2644.061627\n",
            "Epoch Step: 1100 Loss: 3.801679 Tokens per Sec: 2717.630626\n",
            "Epoch Step: 1200 Loss: 14.850591 Tokens per Sec: 2642.992227\n",
            "Epoch Step: 1300 Loss: 10.251930 Tokens per Sec: 2586.275509\n",
            "Epoch Step: 1400 Loss: 6.893307 Tokens per Sec: 2683.120339\n",
            "Epoch Step: 1500 Loss: 4.361377 Tokens per Sec: 2668.420080\n",
            "Epoch Step: 1600 Loss: 8.691318 Tokens per Sec: 2659.160985\n",
            "Epoch Step: 1700 Loss: 7.183273 Tokens per Sec: 2583.919704\n",
            "Epoch Step: 1800 Loss: 3.207075 Tokens per Sec: 2593.152418\n",
            "Epoch Step: 1900 Loss: 5.882164 Tokens per Sec: 2443.460555\n",
            "Epoch Step: 2000 Loss: 6.493421 Tokens per Sec: 2295.021508\n",
            "Epoch Step: 2100 Loss: 5.970579 Tokens per Sec: 2367.229929\n",
            "Epoch Step: 2200 Loss: 4.696832 Tokens per Sec: 2520.046401\n",
            "Epoch Step: 2300 Loss: 3.679482 Tokens per Sec: 2621.829086\n",
            "Epoch Step: 2400 Loss: 6.893035 Tokens per Sec: 2694.164614\n",
            "Epoch Step: 2500 Loss: 6.122704 Tokens per Sec: 2626.151090\n",
            "Epoch Step: 2600 Loss: 5.488792 Tokens per Sec: 2679.638476\n",
            "Epoch Step: 2700 Loss: 5.788548 Tokens per Sec: 2595.361402\n",
            "Epoch Step: 2800 Loss: 5.225916 Tokens per Sec: 2683.145550\n",
            "Epoch Step: 2900 Loss: 7.472011 Tokens per Sec: 2555.200830\n",
            "Epoch Step: 3000 Loss: 14.533057 Tokens per Sec: 2578.470637\n",
            "Epoch Step: 3100 Loss: 6.366988 Tokens per Sec: 2636.425641\n",
            "Epoch Step: 3200 Loss: 10.794581 Tokens per Sec: 2534.919181\n",
            "Epoch Step: 3300 Loss: 9.302916 Tokens per Sec: 2568.052600\n",
            "\n",
            "Example #1\n",
            "Src :  good afternoon mr. ball :   the enron corp. research group would like to conduct an informal interview with you at your convenience .   please give me some dates and times within the next 2 weeks that you might be available and i will arrange the schedule .   the people that will be interviewing you are :   vince kaminski    managing director stinson gibner    vice president grant masson    vice president vasant shanbhogue   vice president krishna krishnarao   director zimin lu    director tanya tamarchenko   manager alex huang    manager   each individual interview will last approximately 15 - 20 minutes , so we probably should allow at least   3 hours .   if you would prefer to call me with some dates and times - i can check the calendars while we are talking .   look forward to hearing from you .   thank you .   shirley crenshaw administrative coordinator research group 713/853 - 5290\n",
            "Trg :  with enron corp. research group\n",
            "Pred:  <unk> : enron corp. research group\n",
            "\n",
            "Example #2\n",
            "Src :  1 . if you know that you are taking vacation for the holidays , please submit a timesheet <unk> send your timesheet if you have taken time off / rotation information has changed . sorry , we are no longer tracking overtime since you are salary based . to all a / a pool members : it is important that you let us know of any time you have taken off . to those members who are sending time on to your assistant , please make sure they forward that information on to the a / a program . with the roll out of sap , you have the ability to go on - line @ http://ehronline.enron.com/ and input your time . i will continue to email for timesheets regardless if you go on - line . this is to let you know it is time to input your time or fills out your timesheet . 2 . if you have moved recently , please provide the following and indicate the new changes when sending your timesheet . new rotation : business unit and group : effective date : location : extension : supervisor : supervisor 's location : supervisor 's extension : supervisor 's assistant : assistant 's location : assistant 's extension : co # rc # 3 . quick reminder that you can pick up your check or past period check @ eb 1198 ( if they are not already coming to your location / mail stop ) . thank you for your cooperation rt\n",
            "Trg :  / a - timesheets\n",
            "Pred:  <unk> for the year 's desk\n",
            "\n",
            "Example #3\n",
            "Src :  peter and dan--   txu is in the process of amending the current guaranty to have the cap amount increased due to an increase in trading .   please review the attached document and send any commentary back to my attention .   the beneficiaries involved are both enron north america corp. and enron canada corp.   i would appreciate a prompt response in order to have the guaranty executed as soon as possible by the counterparty due to the current exposure that we currently have out to them .     thank you ,   veronica espinoza\n",
            "Trg :  energy trading -- guaranty\n",
            "Pred:  guaranty\n",
            "\n",
            "Validation perplexity: 25.908397\n",
            "Epoch 9\n",
            "Epoch Step: 100 Loss: 5.027025 Tokens per Sec: 2546.154578\n",
            "Epoch Step: 200 Loss: 1.680248 Tokens per Sec: 2663.003844\n",
            "Epoch Step: 300 Loss: 3.705888 Tokens per Sec: 2582.930991\n",
            "Epoch Step: 400 Loss: 9.063460 Tokens per Sec: 2663.683665\n",
            "Epoch Step: 500 Loss: 7.419744 Tokens per Sec: 2661.570322\n",
            "Epoch Step: 600 Loss: 4.620015 Tokens per Sec: 2691.200753\n",
            "Epoch Step: 700 Loss: 0.460077 Tokens per Sec: 2591.789136\n",
            "Epoch Step: 800 Loss: 4.404256 Tokens per Sec: 2635.082191\n",
            "Epoch Step: 900 Loss: 4.382694 Tokens per Sec: 2623.888396\n",
            "Epoch Step: 1000 Loss: 7.467493 Tokens per Sec: 2598.995701\n",
            "Epoch Step: 1100 Loss: 6.190669 Tokens per Sec: 2576.157190\n",
            "Epoch Step: 1200 Loss: 3.315538 Tokens per Sec: 2552.823186\n",
            "Epoch Step: 1300 Loss: 4.727669 Tokens per Sec: 2427.505181\n",
            "Epoch Step: 1400 Loss: 7.864166 Tokens per Sec: 2328.728360\n",
            "Epoch Step: 1500 Loss: 7.153136 Tokens per Sec: 2448.454264\n",
            "Epoch Step: 1600 Loss: 5.013111 Tokens per Sec: 2701.286181\n",
            "Epoch Step: 1700 Loss: 3.069095 Tokens per Sec: 2682.587693\n",
            "Epoch Step: 1800 Loss: 4.440977 Tokens per Sec: 2590.402402\n",
            "Epoch Step: 1900 Loss: 4.428820 Tokens per Sec: 2616.531227\n",
            "Epoch Step: 2000 Loss: 10.782289 Tokens per Sec: 2646.940381\n",
            "Epoch Step: 2100 Loss: 7.568232 Tokens per Sec: 2704.974601\n",
            "Epoch Step: 2200 Loss: 7.998357 Tokens per Sec: 2673.843436\n",
            "Epoch Step: 2300 Loss: 3.792451 Tokens per Sec: 2561.846655\n",
            "Epoch Step: 2400 Loss: 5.357273 Tokens per Sec: 2676.183073\n",
            "Epoch Step: 2500 Loss: 4.578969 Tokens per Sec: 2668.438987\n",
            "Epoch Step: 2600 Loss: 5.398382 Tokens per Sec: 2619.451188\n",
            "Epoch Step: 2700 Loss: 7.663218 Tokens per Sec: 2620.416269\n",
            "Epoch Step: 2800 Loss: 4.816466 Tokens per Sec: 2556.560641\n",
            "Epoch Step: 2900 Loss: 4.158280 Tokens per Sec: 2603.756226\n",
            "Epoch Step: 3000 Loss: 4.982477 Tokens per Sec: 2343.646378\n",
            "Epoch Step: 3100 Loss: 8.469717 Tokens per Sec: 2266.909781\n",
            "Epoch Step: 3200 Loss: 4.526480 Tokens per Sec: 2415.075783\n",
            "Epoch Step: 3300 Loss: 2.033262 Tokens per Sec: 2332.663600\n",
            "\n",
            "Example #1\n",
            "Src :  good afternoon mr. ball :   the enron corp. research group would like to conduct an informal interview with you at your convenience .   please give me some dates and times within the next 2 weeks that you might be available and i will arrange the schedule .   the people that will be interviewing you are :   vince kaminski    managing director stinson gibner    vice president grant masson    vice president vasant shanbhogue   vice president krishna krishnarao   director zimin lu    director tanya tamarchenko   manager alex huang    manager   each individual interview will last approximately 15 - 20 minutes , so we probably should allow at least   3 hours .   if you would prefer to call me with some dates and times - i can check the calendars while we are talking .   look forward to hearing from you .   thank you .   shirley crenshaw administrative coordinator research group 713/853 - 5290\n",
            "Trg :  with enron corp. research group\n",
            "Pred:  - enron corp. research group\n",
            "\n",
            "Example #2\n",
            "Src :  1 . if you know that you are taking vacation for the holidays , please submit a timesheet <unk> send your timesheet if you have taken time off / rotation information has changed . sorry , we are no longer tracking overtime since you are salary based . to all a / a pool members : it is important that you let us know of any time you have taken off . to those members who are sending time on to your assistant , please make sure they forward that information on to the a / a program . with the roll out of sap , you have the ability to go on - line @ http://ehronline.enron.com/ and input your time . i will continue to email for timesheets regardless if you go on - line . this is to let you know it is time to input your time or fills out your timesheet . 2 . if you have moved recently , please provide the following and indicate the new changes when sending your timesheet . new rotation : business unit and group : effective date : location : extension : supervisor : supervisor 's location : supervisor 's extension : supervisor 's assistant : assistant 's location : assistant 's extension : co # rc # 3 . quick reminder that you can pick up your check or past period check @ eb 1198 ( if they are not already coming to your location / mail stop ) . thank you for your cooperation rt\n",
            "Trg :  / a - timesheets\n",
            "Pred:  k # 's <unk> !\n",
            "\n",
            "Example #3\n",
            "Src :  peter and dan--   txu is in the process of amending the current guaranty to have the cap amount increased due to an increase in trading .   please review the attached document and send any commentary back to my attention .   the beneficiaries involved are both enron north america corp. and enron canada corp.   i would appreciate a prompt response in order to have the guaranty executed as soon as possible by the counterparty due to the current exposure that we currently have out to them .     thank you ,   veronica espinoza\n",
            "Trg :  energy trading -- guaranty\n",
            "Pred:  \n",
            "\n",
            "Validation perplexity: 29.230842\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Y_XxpNlhnGTh",
        "colab_type": "code",
        "outputId": "38ef59e9-3823-404d-cb80-59bb1ad1897f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "cell_type": "code",
      "source": [
        "plot_perplexity(dev_perplexities)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEWCAYAAAB1xKBvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3XecFeX5///Xm14WhC0gvS0WRFlw\npS1GRY1oEjWxgb1E1F/yiSXF6C+JKZqYolFjidjbR1DU2FE+RpQiZUGqIL0tCEvvZXev7x9nVg/r\nlrOwhzl7zvV8PM5j58zMPXPtUc61c98z9yUzwznnnKtKnbADcM45Vzt4wnDOORcTTxjOOedi4gnD\nOedcTDxhOOeci4knDOecczHxhOGSmqRxkn5cA8eZJ+nUGggpKUkySdlhx+HiyxOGO+wkLZe0W9IO\nSeskPSspLey4KmNmx5nZOABJv5f0YsghVajM51v6ejjsuFzt5wnDheUHZpYG9AFygd9U9wCS6tV4\nVLWIIir6N/wDM0uLev30sAbnkpInDBcqMysA3gd6Akg6QtJTktZKKpB0t6S6wbarJU2U9E9JG4Hf\nR617WNJWSQsknV7R+SRdK2m+pM2SPpDUKVg/UNIGSR2C972CfY4J3i+XdIakIcCdwCXBX+6zJF0k\naXqZ89wm6c0KYhgn6S+SpkraJulNSelR2/tLmiRpS3D8U8u0vUfSRGAX0LU6n3dVn5ektpLekrRJ\n0mJJ10dtqyvpTklLJG2XNL308wqcIWlREPcjklSd2Fzi84ThQhV84ZwDfB6sehYoArKB3sB3gegx\niH7AUqA1cE/UuiVAJnAX8Hr0F3DUuc4j8mX/IyALGA+8DGBmk4DHgeckNQZeBH5rZguij2FmY4A/\nA6OCv9x7AW8BXSQdG7XrFcDzlfzqVwLXAm2C3/ehIMZ2wLvA3UA68AvgNUlZZY49HGgGrKjkHBWp\n7PMaCawG2gIXAn+WNDjYdhswjMh/r+ZB/Luijvt94CTgBOBi4KyDiM0lMjPzl78O6wtYDuwAthD5\nwnsUaEwkCewFGkftOwz4OFi+GlhZ5lhXA2sARa2bClwRLI8Dfhwsvw9cF7VfHSJfeJ2C9/WB6cAc\nYEyZYy4HzgiWfw+8WCaOx4B7guXjgM1Awwp+/3HAvVHvewD7gLrA7cALZfb/ALgqqu0fq/H5lr6u\nr+rzAjoAxUCzqG1/AZ4Nlr8EzqvgnAYMinr/CvDrsP9f81fNvvwKw4XlfDNrYWadzOz/M7PdQCci\nX9prg26NLUT+6m8V1W5VOccqsOBbKrCCyF/IZXUCHow69iZAQDsAM9tP5AqnJ3BfmWNW5Tng0qAb\n5grgFTPbW8n+0b/HCiK/d2YQ40WlMQZxDiJyJVJe24qUfr6lryeitlX0ebUFNpnZ9jLb2gXLHYhc\nmVTkq6jlXUBC38jgqs8Thkskq4hcYWRGfdE1N7PjovYp70u8XZn+8o5E/oou7/g3lPkibWyR7qjS\n7qC7gGeA+yQ1rCDOb8VgZpOJXCWcDFwKvFD5r0p0339HYD+wIYjxhTIxNjWzeys7fzVV9HmtAdIl\nNSuzrSBYXgV0O8Rzu1rME4ZLGGa2FviQyJd1c0l1JHWTdEoVTVsBP5NUX9JFwLHAe+Xs92/gDknH\nwdcD7BcFyyJydfEUcB2wFvhTBedbB3Qu5w6l54GHgf1mNqGKmC+X1ENSE+CPwGgzKyYydvIDSWcF\ng8yNJJ0qqX0Vx6uOcj8vM1sFTAL+Epz3BCKfRektxE8Cf5LUPXKDlk6QlFGDcbkE5wnDJZorgQbA\nF0TGAUZzYHdMeaYA3Yn8hX4PcKGZbSy7k5m9AfwVGClpGzAXODvY/DMiX6S/DbprrgGukXRyOed7\nNfi5UdKMqPUvEOnOiuUZjReIJKivgEbB+Qm+tEsH5wuJ/FX/S6r/b/VtHfgcxhtR2yr7vIYBnYlc\nbbwB3GVm/xdsu5/I2MSHwDYiybVxNeNytZiq103rXGKRdDWRQe1BCRBLY2A90MfMFlWy3zgig+ZP\nHq7Yos59NQnyebnax68wnKs5NwHTKksWztVmKf2krHM1RdJyIndcnR9yKM7FjXdJOeeci4l3STnn\nnItJUnVJZWZmWufOncMOwznnao3p06dvMLOsqvdMsoTRuXNn8vPzww7DOedqDUkxz0fmXVLOOedi\n4gnDOedcTDxhOOeci4knDOecczHxhOGccy4mnjCcc87FxBOGc865mKR8wthbVMzjnyxhwqINYYfi\nnHMJLeUTRv06dRjx6VJem7E67FCccy6hxe1Jb0mNgE+BhsF5RpvZXZLGA6UlIFsBU83sWzN8SioG\n5gRvV5rZufGIs04dMTA7k4mLN2BmHFi50jnnXKl4Tg2yFxhsZjsk1QcmSHrfzL6uYCbpNeDNCtrv\nNrOcOMb3tbxuGbw9aw2L1++ge+tmVTdwzrkUFLcuKYvYEbytH7y+nktdUnNgMPCfeMUQq7zsTAAm\nLvZxDOecq0hcxzCCIvYziZStHGtmU6I2nw98ZGbbKmjeSFK+pMmSKixKI2l4sF9+YWHhQcXZIb0J\nHdObMHHJt8pAO+ecC8Q1YZhZcdCt1B7oK6ln1OZhwMuVNO9kZrnApcADkrpVcI4RZpZrZrlZWTHN\n0FuuvOwMJi/ZSFFxyUEfwznnktlhuUvKzLYAHwNDACRlAn2BdytpUxD8XAqMA3rHM8a87Ey27y1i\nTsHWeJ7GOedqrbglDElZkloEy42BM4EFweYLgXfMbE8FbVtKahgsZwJ5wBfxihVgQNcMACZ5t5Rz\nzpUrnlcYbYCPJc0GphEZw3gn2DaUMt1RknIlPRm8PRbIlzSLyJXJvWYW14SRkdaQY9s09wf4nHOu\nAnG7rdbMZlNBN5KZnVrOunzgx8HyJOD4eMVWkUHZGTw3aQW79xXTuEHdw31655xLaCn/pHe0gdmZ\n7CsuIX/FprBDcc65hOMJI0rfzunUrysmLvZxDOecK8sTRpSmDevRu0NLJi3xcQznnCvLE0YZA7Mz\nmFOwlS279oUdinPOJRRPGGUMys7EDCYv9W4p55yL5gmjjF4dWtC0QV0fx3DOuTI8YZRRv24d+nZJ\n94kInXOuDE8Y5cjLzmTphp2s2bI77FCccy5heMIoh0937pxz3+YJoxxHt25GZloDn1fKOeeieMIo\nR506YkC3b8q2Ouec84RRobxuGazfvpfF63dUvbNzzqUATxgV8HEM55w7kCeMCpSWbZ3gz2M45xzg\nCaNSedmZTFnqZVudcw48YVQqLzvDy7Y651zAE0YlSsu2+jiGc87Ft6Z3I0lTJc2SNE/SH4L1z0pa\nJmlm8MqpoP1VkhYFr6viFWdlMtIa0qNNc59XyjnniGOJVmAvMNjMdkiqD0yQ9H6w7ZdmNrqihpLS\ngbuAXMCA6ZLeMrPNcYy3XHlettU554A4XmFYROlDDPWDV6xPwZ0FjDWzTUGSGAsMiUOYVfKyrc45\nFxHXMQxJdSXNBNYTSQBTgk33SJot6Z+SGpbTtB2wKur96mBdeecYLilfUn5hYWGNxg9ettU550rF\nNWGYWbGZ5QDtgb6SegJ3AMcAJwHpwO2HeI4RZpZrZrlZWVmHHHNZpWVbfeDbOZfqDstdUma2BfgY\nGGJma4Puqr3AM0DfcpoUAB2i3rcP1oUiLzuTuWu8bKtzLrXF8y6pLEktguXGwJnAAkltgnUCzgfm\nltP8A+C7klpKagl8N1gXirzsDC/b6pxLefG8wmgDfCxpNjCNyBjGO8BLkuYAc4BM4G4ASbmSngQw\ns03An4J204A/ButCUVq2dYJ3SznnUljcbqs1s9lA73LWD65g/3zgx1Hvnwaejld81VG/bh36dc1g\nkg98O+dSmD/pHaOB3TK8bKtzLqV5wojRoO4+3blzLrV5woiRl211zqU6TxgxkiJlWyd42VbnXIry\nhFENg7IzKPSyrc65FOUJoxoGdvNxDOdc6vKEUQ1ettU5l8o8YVSTl211zqUqTxjV5GVbnXOpyhNG\nNfk4hnMuVXnCqKb0pg28bKtzLiV5wjgIedkZTF+xmd37isMOxTnnDhtPGAchz8u2OudSkCeMg9C3\ni5dtdc6lHk8YB6FJAy/b6pxLPZ4wDpKXbXXOpZp4lmhtJGmqpFmS5kn6Q7D+JUlfSpor6WlJ9Sto\nXyxpZvB6K15xHqzSsq2f+ey1zrkUEc8rjL3AYDPrBeQAQyT1B14CjgGOBxoTVWWvjN1mlhO8zo1j\nnAeltGzrxCXeLeWcSw3xLNFqQOm0rvWDl5nZe6X7SJoKtI9XDPHkZVudc6kmrmMYkupKmgmsB8aa\n2ZSobfWBK4AxFTRvJClf0mRJ51dyjuHBfvmFhYU1Gn9VvGyrcy6VxDVhmFmxmeUQuYroK6ln1OZH\ngU/NbHwFzTuZWS5wKfCApG4VnGOEmeWaWW5WVlaNxl8VL9vqnEslh+UuKTPbAnwMDAGQdBeQBdxW\nSZuC4OdSYBzQO+6BVpOXbXXOpZJ43iWVJalFsNwYOBNYIOnHwFnAMDMrd45wSS0lNQyWM4E84It4\nxXqwJDHQy7Y651JEPK8w2gAfS5oNTCMyhvEO8G+gNfBZcMvs7wAk5Up6Mmh7LJAvaRaRK5N7zSzh\nEgZEbq/1sq3OuVQQz7ukZlNON5KZlXtOM8snuMXWzCYRue024ZVOdz5h8Qa6t24WcjTOORc//qT3\nIeqQ3oROGU18XinnXNLzhFEDBnbzsq3OueTnCaMGlJZtne1lW51zScwTRg0oHceY5M9jOOeSmCeM\nGuBlW51zqcATRg0Z1D3Ty7Y655KaJ4waMrBbhpdtdc4lNU8YNaS0bOsEH8dwziUpTxg1pEmDevTu\n2NKnO3fOJS1PGDUor5uXbXXOJS9PGDVoUHcv2+qcS16eMGrQCe29bKtzLnl5wqhBXrbVOZfMPGHU\nsLzsTC/b6pxLSp4walhedgbgZVudc8nHE0YNKy3b6gnDOZdsYkoYku6TdFx1DiypkaSpkmZJmifp\nD8H6LpKmSFosaZSkBhW0vyPY50tJZ1Xn3GEqLds6cclGL9vqnEsqsV5hzAdGBF/0N0o6IoY2e4HB\nZtYLyAGGSOoP/BX4p5llA5uB68o2lNQDGAocBwwBHpVUN8ZYQ+dlW51zySimhGFmT5pZHnAl0BmY\nLel/JZ1WSRszs9JvzPrBy4DBwOhg/XPA+eU0Pw8YaWZ7zWwZsBjoG0usiSAv+5uyrc45lyxiHsMI\n/sI/JnhtAGYBt0kaWVkbSTOB9cBYYAmwxcyKgl1WA+3KadoOWBX1vqL9kDRcUr6k/MLCwlh/nbhq\n39LLtjrnkk+sYxj/BBYA5wB/NrMTzeyvZvYDoHdF7cys2MxygPZErhCOqYGYy55jhJnlmlluVlZW\nTR/+oHnZVudcson1CmM2kGNmN5jZ1DLbquwqMrMtwMfAAKCFpHrBpvZAQTlNCoAOUe8r2i9hDcrO\n9LKtzrmkEmvCuNzMdkavkPQRgJmV+40oKUtSi2C5MXAmkcHzj4ELg92uAt4sp/lbwFBJDSV1AboD\nZRNVQhvQLfI8hpdtdc4li0oTRnBrbDqQKamlpPTg1ZkKxhSitAE+ljQbmAaMNbN3gNuJjH0sBjKA\np4JznSvpjwBmNg94BfgCGAP8xMxqVSm70rKtPvDtnEsW9arYfgNwC9AWmBG1fhvwcGUNzWw25Yxv\nmNlSyunGMrO3iFxZlL6/B7inivgS2qDumTw7cTm79xXTuEGtuSvYOefKVekVhpk9aGZdgF+YWZeo\nVy8zqzRhOC/b6pxLLlV1SQ0OFgsk/ajs6zDEV6t52VbnXLy9P2ctd74xh5KS+M8sUVWX1CnAf4Ef\nlLPNgNdrPKIk4mVbnXPx9O7stfxs5OfkdGjBnqJimjSo6iv90FR6dDO7K/h5TVyjSGJ53TJ54KOF\nbNm1jxZNyp02yznnqu2d2Wu4eeRMendowbPX9o17soDYH9x7IXr+KEmdSm+rdZXzsq3OuZr29qxI\nsujTMZIs0hrGP1lA7M9hTACmSDpH0vVEpvl4IH5hJQ8v2+qcq0lvzVrDzSM/58SOLXn2msOXLKDq\nMQwAzOxxSfOIPHS3AehtZl/FNbIkUb9uHfp3zfB5pZxzh+zNmQXcOmomuZ3Teebqk2h6GJMFxN4l\ndQXwNJHZap8F3pPUK45xJZWB2Zks87KtzrlD8J/PI8mib5d0nr3m8CcLiL1L6gJgkJm9bGZ3ADcS\nmZrcxcDLtjrnDsUbn6/mtldm0q9LBk9ffdJhGeAuT6z1MM43s/VR76dSi+pThM3LtjrnDtZr01dz\n2yuz6N813GQBsXdJHSXpI0lzg/cnAL+Ka2RJxMu2OucOxujpq/nF6FkM7JbBU1edFPoUQ7F2ST0B\n3AHsh6/niRoar6CSUWnZ1kVettU5F4NX8lfxy9GzyOuWmRDJAmJPGE3KqYNRVO6erlylZVu9W8o5\nV5VXpq3i9tdmMyg7kyevyqVR/fCTBcSeMDZI6kZkOhAkXQisjVtUScjLtjrnYjFq2kp+9dpsTu6e\nxRNXJk6ygBifwwB+AowAjpFUACwDLo9bVEkqLzuTt2euoai4hHp1Yy6n7pxLES9PXckdr8/hlKOy\nePyKExMqWUDsd0ktNbMzgCzgGDMbZGbL4xpZEsrr5mVbnXPl+98pkWRx6tGJmSygiisMSbdVsB4A\nM7u/krYdgOeB1kS6skaY2YOSRgFHB7u1ALaYWU457ZcD24FioMjMcqv6ZRJdadnWiYs20Kdjy5Cj\ncc4lihcnr+A3/5nLaUdn8e8rTqRhvcRLFlB1l1SzQzh2EfBzM5shqRkwXdJYM7ukdAdJ9wGV/bl9\nmpklzShxetMGHNe2OROXbOB/Tu8edjjOuQTwwuQV/PY/cxl8TCseu7xPwiYLqHp68z8c7IHNbC3B\nwLiZbZc0n0gd8C8AFLlMuRgYXOFBklBetpdtdc5FPP/Zcn735jzOOLYVj1yW2MkCYn9wr6uktyUV\nSlov6U1JXWM9iaTOROp7T4lafTKwzswWVdDMgA8lTZc0PNZzJbrSsq3TlnvZVudS2XOTSpNFax69\nLHG7oaLFeqvO/wKvAG2AtsCrwMuxNJSUBrwG3GJm26I2DaviGIPMrA9wNvATSd+p4PjDJeVLyi8s\nLIwlpFCVlm316c6dS13PTFzGXW/N48werXn0sj40qFc77pqszoN7L5hZUfB6EWhUVSNJ9Ykki5fM\n7PWo9fWAHwGjKmprZgXBz/XAG1Qwd5WZjTCzXDPLzcrKivHXCY+XbXUutT09YRl/ePsLzjquNY9c\nWnuSBcSeMN6X9GtJnYNqe78iMsV5uqT08hoEYxRPAfPLuZvqDGCBma2uoG3TYKAcSU2B7wJzY4w1\n4Q3KzmTumq1s2bUv7FCcc4fRk+OX8sd3vmDIcUfycC1LFhB7wrgYuIFIAaVxwE1E5pKaDuRX0CYP\nuAIYLGlm8Don2DaUMt1RktpKei942xqYIGkWMBV418zGxBhrwsvL9rKtzqWaJ8cv5e5353N2zyP5\n16W9qV8LH96t8klvSXWAy81sYnUObGYTAFWw7epy1q0BzgmWlwJJW6CptGzrhMUbOPv4NmGH45yL\nsyc+Xco9783ne8e34YGhObUyWUAMVxhmVgI8fBhiSRmlZVsn+RWGc0nv8U+WRJLFCbU7WUDsXVIf\nSbpApY94u0NWWra1wMu2Ope0Hhu3hL+8v4Af9GrLg5fU7mQBsSeMG4jcSrtP0jZJ2yVtq6qRq9gg\nn+7cuaT26LjF/HXMAs7t1ZZ/XtwrKSYcjXXywWZmVsfM6ptZ8+B983gHl8yOap1GZlpDJnnCcC7p\nPPLxYv425kvOy2nL/UmSLCD2J70l6XJJvw3ed5DkNb0PQaRsa4aXbXUuyfzro0X8/YMvOT+nLfdf\nnJM0yQJi75J6FBgAXBq83wE8EpeIUsig7Ewv2+pcEnnoo0XcN3YhP+rdjvsuzqFuneQa9o01YfQz\ns58AewDMbDPQIG5RpYiB2cF0594t5Vyt98D/LeT+sQv5UZ92/P2iXkmXLCD2hLFfUl2+KdGaBZTE\nLaoU8U3ZVk8YztVm/xy7kAf+bxEXntiev1+YnMkCYk8YDxGZz6mVpHuACcCf4xZVCsnLzmTK0k0U\nFXv+da62MTPuH7uQBz9axEUntuevF5yQtMkCYr9L6iXgV8BfiNS4ON/MXo1nYKnCy7Y6VzuVJouH\nPlrExbnJnyyg6hKtjYAbgWxgDvC4mRUdjsBSxYBuGUhettW52sTM+NsHX/LYuCUMPakDf/7h8dRJ\n8mQBVV9hPAfkEkkWZwP/iHtEKSa9aQN6tGnu9TGcqyXMjD+9M5/Hxi3h0n4dUyZZQNWTD/Yws+MB\nJD1FZOZYV8O8bKtztUNJifHbN+fy0pSVXJPXmd99vwepNGNSVVcY+0sXvCsqfvKyM71sq3MJrrjE\n+NVrs3lpykpuPKVbyiULqDph9ArmjtomaTtwgs8lVfNO6tzSy7Y6l8CKiku4ddRMRk9fzS1ndOf2\nIUenXLKAKrqkzMz7Rw6DJg3q0adjS38ew7kEtK+ohJ+9/Dlj5n3F7UOO4aZTu4UdUmiSZ5KTWi4v\nO5N5a7Z52VbnEsie/cXc+OJ0xsz7it99v0dKJwuIY8IIJij8WNIXkuZJujlY/3tJBeWUbS3bfoik\nLyUtlvTreMWZKPKyMzGDd2avDTsU5xywe18x1z+fz38XrOfu83ty7aAuYYcUunheYRQBPzezHkB/\n4CeSegTb/mlmOcHrvbINg2lIHiFyK28PYFhU26TUu0ML+nVJ5y/vzWflxl1hh+NcStuxt4irnpnK\nxMUb+PuFJ3B5/05hh5QQ4pYwzGytmc0IlrcD84F2MTbvCyw2s6Vmtg8YCZwXn0gTQ5064v5LcqhT\nR9z6ykyfKsS5kGzbs58rn5rC9BWbeWBoby7K7RB2SAnjsIxhSOoM9AamBKt+Kmm2pKcllfd4cztg\nVdT71VSQbCQNl5QvKb+wsLAGoz782rVozN3n92T6is08Om5J2OE4l3I279zHZU9MYU7BVh65tA/n\n9mobdkgJJe4JQ1Ia8Bpwi5ltAx4DugE5ROaluu9Qjm9mI8ws18xys7KyDjnesJ2X047zctry4EeL\n+Hzl5rDDcS5lbNixl2FPTObLddt5/IoTGdLzyLBDSjhxTRiS6hNJFi+Z2esAZrbOzIrNrAR4gkj3\nU1kFQPR1YPtgXUr443k9ObJ5I24dNZOde/15Sefibd22PQwdMZnlG3fy9FUnMfiY1mGHlJDieZeU\ngKeA+WZ2f9T6NlG7/RCYW07zaUB3SV0kNQCGAm/FK9ZEc0Tj+tx/cS9WbNrFn975IuxwnEtqBVt2\nc8njn7F2y26eu6Yvg7pnhh1SwornFUYecAUwuMwttH+TNEfSbOA04FYASW0lvQdfT0PyU+ADIoPl\nr5jZvDjGmnD6dc3gplO6MXLaKsbM/SrscJxLSqs27eKSxz9j4459PH9dP/p1zQg7pIQmMws7hhqT\nm5tr+fn5YYdRY/YVlfCjxyZSsHk3H9zyHVo1bxR2SM4ljaWFO7j0iSnsKSrmhWv7cXz7I8IOKRSS\npptZbiz7+pPeCaxBvTo8cElvdu8v5hejZ1NSkjzJ3bkwLVy3nYsfn8z+4hJevr5/yiaL6vKEkeCy\nW6Xxm+/14NOFhTz32fKww3Gu1pu3ZitDR0ymjmDUDf05tk3zsEOqNTxh1AKX9evI6ce04i/vL+DL\nr7aHHY5ztdasVVsYNmIyjerV4ZUbBpDdqlnYIdUqnjBqAUn89cITaN6oHjeP/Jy9RcVhh+RcrZO/\nfBOXPTmFI5rUZ9QNA+ic2TTskGodTxi1RGZaQ/5+YS8WfLWdf3zwZdjhOFerTFqygSufnkqrZg15\n5YYBdEhvEnZItZInjFrktGNacUX/TjwxfpnXznAuRp8sLOSaZ6bRvmVjRt7QnzZHNA47pFrLE0Yt\nc+c5x9Itqyk/f2WW185wrgpjv1jH9c/l0y0rjZHDB9Cqmd+afig8YdQyjRvU5cGhvdm4cy93vjGH\nZHqOxrma9O7stdz04nSObdOMl6/vT3rTBmGHVOt5wqiFerY7gtvOPJr35nzFazNSZoot52L2xuer\n+Z+XZ5DToQUv/rgfRzSpH3ZIScETRi01/Dtd6dclnbvenOsFl5yLMmraSm57ZRb9umTw3LV9adbI\nk0VN8YRRS9WNKrh0y6jPveCSc8Dzny3n9tfmcHL3LJ655iSaNqwXdkhJxRNGLVZacGnGyi1ecMml\nvCfHL+V3b87jjGNb88SVJ9Koft2wQ0o6njBqufNy2nG+F1xyKe7h/y7i7nfn873j2/DY5X1oWM+T\nRTx4wkgCf/CCSy5FmRn3ffgl//hwIT/s3Y4Hh+ZQv65/rcWLf7JJILrg0h/f9oJLLjWYGX9+bz7/\n+u9ihp7UgX9c1It6niziyj/dJFFacGlUvhdccsmvpMS46615PDF+GVcO6MSff3g8deso7LCSXjxL\ntHaQ9LGkLyTNk3RzsP7vkhZImi3pDUktKmi/PKjMN1NS8lRFiqNbzjiK49sdwR2vz2bdtj1hh+Nc\nXBQVl3DnG3N4/rMVXH9yF/5w7nHU8WRxWMTzCqMI+LmZ9QD6Az+R1AMYC/Q0sxOAhcAdlRzjNDPL\nibUaVKprUK8O/7wkJ1Jw6dVZXnDJJZ1Vm3YxdMRkRk5bxU9Py+bOc45F8mRxuMQtYZjZWjObESxv\nJ1Kbu52ZfRjU7AaYDLSPVwypqLTg0vhFG3h20vKww3Guxrw5s4BzHhzPgq+288AlOfzirKM9WRxm\nh2UMQ1JnoDcwpcyma4H3K2hmwIeSpksaXsmxh0vKl5RfWFhYE+HWeqUFl+4d4wWXXO23fc9+bhs1\nk5tHzqR76zTev/lkzu/dLuywUlLcE4akNOA14BYz2xa1/v8n0m31UgVNB5lZH+BsIt1Z3ylvJzMb\nYWa5ZpablZVVw9HXTl5wySWLGSs3872HJvCfmQXcfHp3r2URsrgmDEn1iSSLl8zs9aj1VwPfBy6z\nCqZbNbOC4Od64A2gbzxjTTbRBZf+PsYLLrnapbjEeOijRVz0788oLjFeuWEAt555lN82G7J43iUl\n4ClgvpndH7V+CPAr4FwzK3eVkxF2AAAQNElEQVTWPElNJTUrXQa+C8yNV6zJqrTg0pMTljFhkRdc\ncrVDwZbdDBsxmfvHLuR7x7fh/VtOJrdzethhOeJ7hZEHXAEMDm6NnSnpHOBhoBkwNlj3bwBJbSW9\nF7RtDUyQNAuYCrxrZmPiGGvS+rrg0qszveCSS3hvz1rDkAc+5Yu127j/4l48ODSH5j7bbMJQMhXg\nyc3Ntfx8f2SjrLkFW/nhoxM5s0drHrm0j99Z4hLOjr1F3PXmPF6bsZreHVvw4CW96ZjhYxWHg6Tp\nsT664B2CKSC64NLo6avDDse5A8xctYXvPTSeNz5fzc8GZ/PKDQM8WSQoTxgporTg0u/fmseKjTvD\nDsc5ikuMh/+7iAsem0RRsTFy+ABu++7RPnlgAvP/MikiuuDSraNmesElF6o1W3Yz7InJ/OPDhZzd\n80jeu/lk+nbxge1E5wkjhUQXXHrkYy+45MLx7uy1DHngU+YVbOUfF/XiX8N6c0RjH9iuDbx+YYo5\nL6cdHy9Yz0P/XcTJR2XSp2PLsENyKWLn3iJ+/9Y8Xp2+ml4dWvDgJTl0zmwadliuGvwKIwX98fxv\nCi7t8IJL7jCYFQxsj56xmp+els3oGwd4sqiFPGGkoOaNIgWXVm7axZ+84JKLo+IS49Fxi7ngsUns\nLSrh5ev784uzfGC7tvIuqRRVWnDp0XFLOO2YVgzpeWTYIbkks3brbm4dNZPJSzfxvePb8OcfHs8R\nTXysojbzhJHCbjnjKMYv2sCvX59N744taN28UdghuSTx/py1/Pr1OewvLuFvF57ARSe29wdGk4Bf\nF6awBvXq8MDQHPZ4wSVXQ3btK+LXr83mppdm0CmjCe/+7GQuzu3gySJJeMJIcd2yvOCSqxlzVm/l\n+w9NYFT+Km46tRujbxxIFx/YTireJeW4rF9Hxn25nnvHLGBgdgbHHNk87JBcLVJSYowYv5T7PvyS\njKYNeenH/RjYLTPssFwc+BWGQxL3XhApuHTLyJns2e8Fl1xsvtq6hyuensK97y/g9GNaM+aWkz1Z\nJDFPGA4oU3DpAy+45Kr2wbyvGPLgp8xYsYV7f3Q8j13ehxZNGoQdlosj75JyXystuPTUhGUsKdzB\njad0o1+XdB+wdAfYta+IP70zn5enrqRnu+Y8OLQ33bLSwg7LHQaeMNwBfvP9Y2nVrCHPTlrO0BGT\n6dWhBTed0pUzexxJ3TqeOFLd3IKt/Gzk5yzbsJMbTunKz888mgb1vKMiVcStgJKkDsDzRKrnGTDC\nzB6UlA6MAjoDy4GLzWxzOe2vAn4TvL3bzJ6r6pxeQKnm7NlfzKvTV/PEp0tZuWkXXTObcv13uvLD\n3u1oVL9u2OG5w8jMmLZ8M09NWMrYL9aR1awh91+cQ162j1Ukg+oUUIpnwmgDtDGzGUF97unA+cDV\nwCYzu1fSr4GWZnZ7mbbpQD6QSyTZTAdOLC+xRPOEUfOKS4z3567l8U+WMqdgK1nNGnJNXmcu69fJ\nZxhNcvuKSnhvzlqemrCMOQVbadGkPpf27cj1J3elZVMfq0gWCZEwvnUi6U0i9bwfBk41s7VBUhln\nZkeX2XdYsM8NwfvHg/1eruwcnjDix8z4bMlGHvtkCeMXbSCtYT0u7deRa/O6cOQR/oR4Mtm8cx//\nO3Ulz3+2nHXb9tI1qynX5nXhgj7tadzAry6TTXUSxmEZw5DUGegNTAFam9naYNNXRLqsymoHrIp6\nvzpYV96xhwPDATp27FgzAbtvkcTA7EwGZmcyb81WHv9kKU+OX8ozE5dxXk47bvhOV7q3bhZ2mO4Q\nLF6/nacnLuf1GavZs7+Ek7tncu8FJ3BK9yzq+PiV4zAkDElpwGvALWa2LfqOGzMzSYd0iWNmI4AR\nELnCOJRjudgc1/YIHhrWm1+edTRPjl/KqPxVjJ6+mjOObcWNp3Qjt7NXTqstzIzxizbw1IRlfLKw\nkAb16vDDnHZcO6gLRx/pfwC4A8U1YUiqTyRZvGRmrwer10lqE9Ultb6cpgXAqVHv2wPj4hmrq74O\n6U34w3k9ufmMo3hu0nKe/2w5F/77M07s1JIbT+nG6ce08r9ME9Se/cX85/MCnp64jIXrdpCZ1pDb\nzjyKS/t1JDOtYdjhuQQVz0FvAc8RGeC+JWr934GNUYPe6Wb2qzJt04kMdPcJVs0gMui9qbJz+hhG\nuHbtK+KVaat4YvwyCrbsJrtVGsO/05Xzc9r5rZcJYv22PbwweQUvTVnJpp37OLZNc64b1IUf9GpD\nw3o+PpGKEmLQW9IgYDwwBygJVt9JZBzjFaAjsILIbbWbJOUCN5rZj4P21wb7A9xjZs9UdU5PGImh\nqLiEd+es5d+fLGX+2m20bt6Q6wZ1YVjfjjRr5HdWhWHemq08NWEZb89aQ1GJcfoxrbluUBf6d/UH\nM1NdQiSMMHjCSCyl/eP//mQJk5ZspFmjelzevxPXDOxMK6+9EXfFJcZH89fx1IRlTFm2iSYN6nLR\nie25Oq+LzyLrvuYJwyWc2au38PgnS3l/7lrq1anDBSe24/qTu9LVp5SocTv3FvFq/iqembScFRt3\n0a5FY64a2IlLTuroz864b/GE4RLW8g07eWL8Ul6dvpr9xSWc1eNIbjilK707tgw7tFpv9eZdPDdp\nOSOnrWL7niL6dGzBtYO6MOS4I6nnNbRdBTxhuIRXuH0vz3+2nOc/W8HW3fvp1yWdG0/pxqlHZ3mf\nejVNX7GZpycsY8y8rwA4u+eRXDeoiydhFxNPGK7W2Lm3iJHTVvHU+KWs2bqHo1s344ZTuvKDXm2p\n738VV2h/cQnvz/2KpycsY+aqLTRvVI9h/Tpy5YDOtGvROOzwXC3iCcPVOvuLS3h71hoe/2QpX67b\nTtsjGnFpv470bHcER7VuRpsjGvmVB7B1135enraS5yYtZ+3WPXTJbMo1eZ25oE97mjb0yadd9XnC\ncLWWmTHuy0Ie+2QJU5d989hNWsN6ZLdK46jWaRzVuhndWzeje6u0lEgkW3ftZ9nGnbw+YzWv5q9m\n9/5iBnbL4Nq8Lgz2hyPdIfKE4ZLC5p37WLhuO4vW72DRuu0sXLeDReu3s2HHvq/3adawHtmt0+je\n6ptEclTrNI5sXnsSyZ79xRRs2c3KTbtYvWkXqzbvZuXGXazavItVm3axbU8RAA3q1uHcnLZcm9eF\nHm297rqrGZ4wXFLbtHNfJIEEiWRRJYnkqFbN6N46LdREUlJifLVtD6tKk8HXiWEXKzftYt22vQfs\n37BeHdq3bEyH9CZ0TG9Ch5ZN6JDemBM7pZPVzKftcDXLE4ZLSWUTycJ121m8fkeliSRyVXJoicTM\n2Lp7P6s2RZJB6ZXByk27WL15NwWbd7OvuOTr/SVo07wRHdKbRF4tm9Axo3GQGJqQldbQu5ncYeMJ\nw7kom0q7toLurYXBVcnGnVGJpFG9r7u1soOfR7VuRuvmDZHEnv3FrN68i1WbdkeuDL7uMtrNqk27\n2L636IBztmxS/+tkEEkMkYTQMb0JbVs09rm1XMLwhOFcDDbu2Put8ZHyEknj+nVZv/3b3UbfdBk1\nPuBqoUN6Y58zy9UaCVdAyblElJHWkIy0hvTvmnHA+o079rJw3Q4Wr48kkj37iyOJofRKIeg2qi2D\n6s7VFE8YzpWRkdaQAWkNGdAto+qdnUsh3pHqnHMuJp4wnHPOxcQThnPOuZh4wnDOOReTuA16S3oa\n+D6w3sx6ButGAUcHu7QAtphZTjltlwPbgWKgKNZbvpxzzsVPPO+SehZ4GHi+dIWZXVK6LOk+YGsl\n7U8zsw1xi84551y1xC1hmNmnkjqXt02RG9gvBgbH6/zOOedqVlhjGCcD68xsUQXbDfhQ0nRJwys7\nkKThkvIl5RcWFtZ4oM455yLCenBvGPByJdsHmVmBpFbAWEkLzOzT8nY0sxHACABJhZJWHGRMmYB3\ngUX4Z3Eg/zwO5J/HN5Lhs+gU646HPWFIqgf8CDixon3MrCD4uV7SG0BfoNyEUaZd1iHEle+D6xH+\nWRzIP48D+efxjVT7LMLokjoDWGBmq8vbKKmppGaly8B3gbmHMT7nnHPliFvCkPQy8BlwtKTVkq4L\nNg2lTHeUpLaS3gvetgYmSJoFTAXeNbMx8YrTOedcbOJ5l9SwCtZfXc66NcA5wfJSoFe84qrEiBDO\nmaj8sziQfx4H8s/jGyn1WSRVPQznnHPx41ODOOeci4knDOecczFJ+YQhaYikLyUtlvTrsOMJk6QO\nkj6W9IWkeZJuDjumsEmqK+lzSe+EHUvYJLWQNFrSAknzJQ0IO6YwSbo1+HcyV9LLkhqFHVO8pXTC\nkFQXeAQ4G+gBDJPUI9yoQlUE/NzMegD9gZ+k+OcBcDMwP+wgEsSDwBgzO4bIjSkp+7lIagf8DMgN\nJletS+QO0KSW0gmDyAOBi81sqZntA0YC54UcU2jMbK2ZzQiWtxP5QmgXblThkdQe+B7wZNixhE3S\nEcB3gKcAzGyfmW0JN6rQ1QMaBw8jNwHWhBxP3KV6wmgHrIp6v5oU/oKMFkwc2RuYEm4koXoA+BVQ\nEnYgCaALUAg8E3TRPRk8WJuSgtko/gGsBNYCW83sw3Cjir9UTxiuHJLSgNeAW8xsW9jxhEFSaS2X\n6WHHkiDqAX2Ax8ysN7ATSNkxP0ktifRGdAHaAk0lXR5uVPGX6gmjAOgQ9b59sC5lSapPJFm8ZGav\nhx1PiPKAc4NiXiOBwZJeDDekUK0GVptZ6RXnaCIJJFWdASwzs0Iz2w+8DgwMOaa4S/WEMQ3oLqmL\npAZEBq3eCjmm0AR1Sp4C5pvZ/WHHEyYzu8PM2ptZZyL/X/zXzJL+L8iKmNlXwCpJpRUzTwe+CDGk\nsK0E+ktqEvy7OZ0UuAkgrOnNE4KZFUn6KfABkbscnjazeSGHFaY84ApgjqSZwbo7zey9Stq41PE/\nwEvBH1dLgWtCjic0ZjZF0mhgBpG7Cz8nBaYJ8alBnHPOxSTVu6Scc87FyBOGc865mHjCcM45FxNP\nGM4552LiCcM551xMPGE4Vw2SiiXNjHrV2NPOkjpL8vr1LmGl9HMYzh2E3WaWE3YQzoXBrzCcqwGS\nlkv6m6Q5kqZKyg7Wd5b0X0mzJX0kqWOwvrWkNyTNCl6l00rUlfREUGfhQ0mNQ/ulnCvDE4Zz1dO4\nTJfUJVHbtprZ8cDDRGa6BfgX8JyZnQC8BDwUrH8I+MTMehGZk6l0hoHuwCNmdhywBbggzr+PczHz\nJ72dqwZJO8wsrZz1y4HBZrY0mMDxKzPLkLQBaGNm+4P1a80sU1Ih0N7M9kYdozMw1sy6B+9vB+qb\n2d3x/82cq5pfYThXc6yC5erYG7VcjI8zugTiCcO5mnNJ1M/PguVJfFO68zJgfLD8EXATfF03/IjD\nFaRzB8v/enGuehpHzeQLkRrXpbfWtpQ0m8hVwrBg3f8QqVL3SyIV60pneL0ZGCHpOiJXEjcRqdzm\nXMLyMQznakAwhpFrZhvCjsW5ePEuKeecczHxKwznnHMx8SsM55xzMfGE4ZxzLiaeMJxzzsXEE4Zz\nzrmYeMJwzjkXk/8HFZbN441u5l4AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "ZhwXVZ_rnGTk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Prediction and Evaluation\n",
        "\n",
        "Once trained we can use the model to produce a set of translations. \n",
        "\n",
        "If we translate the whole validation set, we can use [SacreBLEU](https://github.com/mjpost/sacreBLEU) to get a [BLEU score](https://en.wikipedia.org/wiki/BLEU), which is the most common way to evaluate translations.\n",
        "\n",
        "#### Important sidenote\n",
        "Typically you would use SacreBLEU from the **command line** using the output file and original (possibly tokenized) development reference file. This will give you a nice version string that shows how the BLEU score was calculated; for example, if it was lowercased, if it was tokenized (and how), and what smoothing was used. If you want to learn more about how BLEU scores are (and should be) reported, check out [this paper](https://arxiv.org/abs/1804.08771).\n",
        "\n",
        "However, right now our pre-processed data is only in memory, so we'll calculate the BLEU score right from this notebook for demonstration purposes.\n",
        "\n",
        "We'll first test the raw BLEU function:"
      ]
    },
    {
      "metadata": {
        "id": "rogqM56C1pT8",
        "colab_type": "code",
        "outputId": "dbebee55-cb96-4bc6-90cd-c2f51f2e367e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install sacrebleu"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: sacrebleu in /usr/local/lib/python3.6/dist-packages (1.3.1)\n",
            "Requirement already satisfied: typing in /usr/local/lib/python3.6/dist-packages (from sacrebleu) (3.6.6)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "5N0sRkOJnGTl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import sacrebleu"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dL8JMn6QnGTp",
        "colab_type": "code",
        "outputId": "84ab37ec-a194-49e1-cd99-6a18a271854c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# this should result in a perfect BLEU of 100%\n",
        "hypotheses = [\"this is a test\"]\n",
        "references = [\"this is a test\"]\n",
        "bleu = sacrebleu.raw_corpus_bleu(hypotheses, [references], .01).score\n",
        "print(bleu)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100.00000000000004\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "gUKBfm5bnGTt",
        "colab_type": "code",
        "outputId": "3f1091f9-bdca-4258-be7d-66a765659dd7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# here the BLEU score will be lower, because some n-grams won't match\n",
        "hypotheses = [\"this is a test\"]\n",
        "references = [\"this is a fest\"]\n",
        "bleu = sacrebleu.raw_corpus_bleu(hypotheses, [references], .01).score\n",
        "print(bleu)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "22.360679774997894\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "tsBr5E2NnGTx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Since we did some filtering for speed, our validation set contains 690 sentences.\n",
        "The references are the tokenized versions, but they should not contain out-of-vocabulary UNKs that our network might have seen. So we'll take the references straight out of the `valid_data` object:"
      ]
    },
    {
      "metadata": {
        "id": "c-G-Ier2nGTy",
        "colab_type": "code",
        "outputId": "6521cd56-f5d9-49ac-d823-8507ed28072c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "len(valid_data)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "19073"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "metadata": {
        "id": "SjU3yHoRnGT0",
        "colab_type": "code",
        "outputId": "d6063f6c-0c14-491d-a524-38253ca647fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "references = [\" \".join(example.trg) for example in valid_data]\n",
        "print(len(references))\n",
        "print(references[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "19073\n",
            "interview with enron corp. research group\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "IQYmEvVNnGT8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Now we translate the validation set!**\n",
        "\n",
        "This might take a little bit of time.\n",
        "\n",
        "Note that `greedy_decode` will cut-off the sentence when it encounters the end-of-sequence symbol, if we provide it the index of that symbol."
      ]
    },
    {
      "metadata": {
        "id": "JB_-herJIwp3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9V3N3kUHnGT8",
        "colab_type": "code",
        "outputId": "2e042fdd-484f-4755-c5d5-8244010bc6d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "hypotheses = []\n",
        "alphas = []  # save the last attention scores\n",
        "for batch in tqdm(valid_iter):\n",
        "  batch = rebatch(PAD_INDEX, batch)\n",
        "  pred, attention = greedy_decode(\n",
        "    model, batch.src, batch.src_mask, batch.src_lengths, max_len=25,\n",
        "    sos_index=TRG.vocab.stoi[SOS_TOKEN],\n",
        "    eos_index=TRG.vocab.stoi[EOS_TOKEN])\n",
        "  hypotheses.append(pred)\n",
        "  alphas.append(attention)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|| 19073/19073 [09:03<00:00, 35.09it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "EiXKOzOU5UNU",
        "colab_type": "code",
        "outputId": "30488535-1d8b-4305-f83e-67671ff05565",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "references[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'interview with enron corp. research group'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "metadata": {
        "id": "Aypot9abnGT9",
        "colab_type": "code",
        "outputId": "ea336e9a-167b-4635-e886-d105788840a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# we will still need to convert the indices to actual words!\n",
        "hypotheses[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([  3,  18, 219, 343, 107])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "metadata": {
        "id": "xjJtrxrynGUA",
        "colab_type": "code",
        "outputId": "c6e6c674-e6fe-4608-9162-16f74be2bb13",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "hypotheses = [lookup_words(x, TRG.vocab) for x in hypotheses]\n",
        "hypotheses[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['-', 'enron', 'corp.', 'research', 'group']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "metadata": {
        "id": "BBN6EV4vnGUC",
        "colab_type": "code",
        "outputId": "82b04776-8307-4526-a97b-418aade1dd4e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "# finally, the SacreBLEU raw scorer requires string input, so we convert the lists to strings\n",
        "hypotheses = [\" \".join(x) for x in hypotheses]\n",
        "print(len(hypotheses))\n",
        "print(hypotheses[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "19073\n",
            "- enron corp. research group\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "pbPThNXanGUD",
        "colab_type": "code",
        "outputId": "d6dc9b6a-26cd-4671-c048-4b6986366227",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# now we can compute the BLEU score!\n",
        "bleu = sacrebleu.raw_corpus_bleu(hypotheses, [references], .01).score\n",
        "print(bleu)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "16.033852468645396\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "UfDpe1QF9SLY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Sv-wR2bi9Sgn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Rouge"
      ]
    },
    {
      "metadata": {
        "id": "o7-j0Y-J-DTh",
        "colab_type": "code",
        "outputId": "28fbf74b-a5a2-456b-94b2-064530fc1c55",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "cell_type": "code",
      "source": [
        "# !pip install py-rouge"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting py-rouge\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9c/1d/0bdbaf559fb7afe32308ebc84a2028600988212d7eb7fb9f69c4e829e4a0/py_rouge-1.1-py3-none-any.whl (56kB)\n",
            "\u001b[K    100% || 61kB 2.8MB/s \n",
            "\u001b[?25hInstalling collected packages: py-rouge\n",
            "Successfully installed py-rouge-1.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "4kvsPlWd-L9z",
        "colab_type": "code",
        "outputId": "10a3d7ce-d576-4b80-89af-d8666ed0d1d0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "import rouge\n",
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "metadata": {
        "id": "-00wegUE9EvL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# references and hypotheses are generated from the last section\n",
        "hyps, refs = references, hypotheses"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jG1vz5-V9VZh",
        "colab_type": "code",
        "outputId": "955029f3-cc10-42e5-da0f-6bc9a4bc07e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 548
        }
      },
      "cell_type": "code",
      "source": [
        "def prepare_results(p, r, f):\n",
        "    return '\\t{}:\\t{}: {:5.2f}\\t{}: {:5.2f}\\t{}: {:5.2f}'.format(metric, 'P', 100.0 * p, 'R', 100.0 * r, 'F1', 100.0 * f)\n",
        "\n",
        "\n",
        "for aggregator in ['Avg', 'Best', 'Individual']:\n",
        "    print('Evaluation with {}'.format(aggregator))\n",
        "    apply_avg = aggregator == 'Avg'\n",
        "    apply_best = aggregator == 'Best'\n",
        "\n",
        "    evaluator = rouge.Rouge(metrics=['rouge-n', 'rouge-l', 'rouge-w'],\n",
        "                           max_n=4,\n",
        "                           limit_length=True,\n",
        "                           length_limit=100,\n",
        "                           length_limit_type='words',\n",
        "                           apply_avg=apply_avg,\n",
        "                           apply_best=apply_best,\n",
        "                           alpha=0.5, # Default F1_score\n",
        "                           weight_factor=1.2,\n",
        "                           stemming=True)\n",
        "\n",
        "    all_hypothesis = hyps\n",
        "    all_references = refs\n",
        "\n",
        "    scores = evaluator.get_scores(all_hypothesis, all_references)\n",
        "\n",
        "    for metric, results in sorted(scores.items(), key=lambda x: x[0]):\n",
        "        if not apply_avg and not apply_best: # value is a type of list as we evaluate each summary vs each reference\n",
        "            for hypothesis_id, results_per_ref in enumerate(results):\n",
        "                nb_references = len(results_per_ref['p'])\n",
        "### skipp printing for individual rouge\n",
        "#                 for reference_id in range(nb_references):\n",
        "#                     print('\\tHypothesis #{} & Reference #{}: '.format(hypothesis_id, reference_id))\n",
        "#                     print('\\t' + prepare_results(results_per_ref['p'][reference_id], results_per_ref['r'][reference_id], results_per_ref['f'][reference_id]))\n",
        "            print()\n",
        "        else:\n",
        "            print(prepare_results(results['p'], results['r'], results['f']))\n",
        "    print()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation with Avg\n",
            "\trouge-1:\tP: 16.01\tR: 25.07\tF1: 18.51\n",
            "\trouge-2:\tP:  8.69\tR: 13.33\tF1: 10.06\n",
            "\trouge-3:\tP:  5.76\tR:  9.20\tF1:  6.70\n",
            "\trouge-4:\tP:  3.95\tR:  5.94\tF1:  4.52\n",
            "\trouge-l:\tP: 17.77\tR: 25.97\tF1: 20.27\n",
            "\trouge-w:\tP: 15.55\tR: 19.89\tF1: 16.07\n",
            "\n",
            "Evaluation with Best\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ZeroDivisionError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-53-1947d5712589>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mall_references\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrefs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_hypothesis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_references\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresults\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/rouge/rouge.py\u001b[0m in \u001b[0;36mget_scores\u001b[0;34m(self, hypothesis, references)\u001b[0m\n\u001b[1;32m    483\u001b[0m         \u001b[0mhas_rouge_w_metric\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmetric\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mmetric\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'-'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhas_rouge_w_metric\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 485\u001b[0;31m             \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_scores_rouge_l_or_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhypothesis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreferences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    486\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    487\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/rouge/rouge.py\u001b[0m in \u001b[0;36m_get_scores_rouge_l_or_w\u001b[0;34m(self, all_hypothesis, all_references, use_w)\u001b[0m\n\u001b[1;32m    626\u001b[0m                             \u001b[0mreference_count_for_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreference_count\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1.0\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight_factor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m                             \u001b[0moverlapping_ngrams_for_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moverlapping_ngrams\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 628\u001b[0;31m                             \u001b[0mscore_wlcs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0moverlapping_ngrams_for_score\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mreference_count_for_score\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1.0\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight_factor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    629\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mbest_current_score_wlcs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mscore_wlcs\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mbest_current_score_wlcs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mZeroDivisionError\u001b[0m: float division by zero"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "fQGctqJvnGUF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Attention Visualization\n",
        "\n",
        "We can also visualize the attention scores of the decoder."
      ]
    },
    {
      "metadata": {
        "id": "auYnZ4slnGUG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def plot_heatmap(src, trg, scores):\n",
        "\n",
        "    fig, ax = plt.subplots()\n",
        "    heatmap = ax.pcolor(scores, cmap='viridis')\n",
        "\n",
        "    ax.set_xticklabels(trg, minor=False, rotation='vertical')\n",
        "    ax.set_yticklabels(src, minor=False)\n",
        "\n",
        "    # put the major ticks at the middle of each cell\n",
        "    # and the x-ticks on top\n",
        "    ax.xaxis.tick_top()\n",
        "    ax.set_xticks(np.arange(scores.shape[1]) + 0.5, minor=False)\n",
        "    ax.set_yticks(np.arange(scores.shape[0]) + 0.5, minor=False)\n",
        "    ax.invert_yaxis()\n",
        "\n",
        "    plt.colorbar(heatmap)\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PVybA0GBnGUI",
        "colab_type": "code",
        "outputId": "52085b3c-955a-457e-d70a-f417b6c28fac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        }
      },
      "cell_type": "code",
      "source": [
        "# This plots a chosen sentence, for which we saved the attention scores above.\n",
        "idx = 5\n",
        "src = valid_data[idx].src + [\"</s>\"]\n",
        "trg = valid_data[idx].trg + [\"</s>\"]\n",
        "pred = hypotheses[idx].split() + [\"</s>\"]\n",
        "pred_att = alphas[idx][0].T[:, :len(pred)]\n",
        "print(\"src\", src)\n",
        "print(\"ref\", trg)\n",
        "print(\"pred\", pred)\n",
        "plot_heatmap(src, pred, pred_att)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "src ['please', 'welcome', 'steve', 'mccarrel', 'to', 'our', 'portland', 'west', 'origination', 'legal', 'team', '.', ' ', 'steve', 'joins', 'us', 'after', 'spending', 'the', 'last', '4', 'years', 'of', 'his', 'practice', 'with', 'enron', 'broadband', 'services', ',', 'and', ',', 'prior', 'to', 'ebs', ',', 'with', 'portland', 'general', '.', ' ', 'he', 'brings', 'with', 'him', 'an', 'abundance', 'of', 'skill', 'sets', 'and', 'experience', 'in', 'transactional', ',', 'finance', 'and', 'project', 'development', 'work', ',', 'and', 'is', 'an', 'outstanding', 'addition', 'to', 'our', 'team', '.', ' ', 'steve', \"'s\", 'office', 'is', 'between', 'karen', \"'s\", 'and', 'christian', \"'s\", ',', 'and', 'jan', 'will', 'provide', 'his', 'admin', 'support', '.', ' ', 'welcome', 'aboard', ',', 'steve', '!', '</s>']\n",
            "ref ['welcome', 'steve', 'mccarrel', '</s>']\n",
            "pred ['<unk>', '</s>']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZsAAAEXCAYAAAB76ulbAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nHFI3AgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "jeRUtXdBnGUO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Congratulations! You've finished this notebook.\n",
        "\n",
        "What didn't we cover?\n",
        "\n",
        "- Subwords / Byte Pair Encoding [[paper]](https://arxiv.org/abs/1508.07909) [[github]](https://github.com/rsennrich/subword-nmt) let you deal with unknown words. \n",
        "- You can implement a [multiplicative/bilinear attention mechanism](https://arxiv.org/abs/1508.04025) instead of the additive one used here.\n",
        "- We used greedy decoding here to get translations, but you can get better results with beam search.\n",
        "- The original model only uses a single dropout layer (in the decoder), but you can experiment with adding more dropout layers, for example on the word embeddings and the source word representations.\n",
        "- You can experiment with multiple encoder/decoder layers.- Experiment with a benchmarked and improved codebase: [Joey NMT](https://github.com/joeynmt/joeynmt)"
      ]
    },
    {
      "metadata": {
        "id": "I7Zo_LC5nGUO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "If this was useful to your research, please consider citing:\n",
        "\n",
        "> Joost Bastings. 2018. The Annotated Encoder-Decoder with Attention. https://bastings.github.io/annotated_encoder_decoder/\n",
        "\n",
        "Or use the following `Bibtex`:\n",
        "```\n",
        "@misc{bastings2018annotated,\n",
        "  title={The Annotated Encoder-Decoder with Attention},\n",
        "  author={Bastings, Joost},\n",
        "  journal={https://bastings.github.io/annotated\\_encoder\\_decoder/},\n",
        "  year={2018}\n",
        "}```"
      ]
    }
  ]
}